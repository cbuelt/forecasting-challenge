{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b11b35a7-c260-49af-96e8-2c198e836ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import date, timedelta, datetime\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_pinball_loss\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from tensorflow.keras.layers import Input, Conv1D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.losses import pinball_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89e94ddf-d369-4193-8974-b237a37260dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "horizons = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1081c7-625d-4061-bea0-b97354708db9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e1545f-73e1-487a-9779-7d58239ffe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "current_day = datetime.today()\n",
    "data = yf.download(\"^GDAXI\", start=\"2000-01-01\", end=current_day)[\"Adj Close\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0dc4a3-53f8-42f3-ac73-8d72ed142f65",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Wavenet modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25079ee-3f4c-45e2-a8fa-5e3b7082ea50",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Add all five horizons as a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10d288a1-4b29-4183-bf20-d2c3a6b8ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep = pd.DataFrame(data)\n",
    "data_prep[\"log_return\"] = 100 * (np.log(data_prep) - np.log(data_prep.shift(1)))\n",
    "for horizon in range(1,6):\n",
    "    data_prep[horizon] = 100 * (np.log(data_prep[\"Adj Close\"]) - np.log(data_prep[\"Adj Close\"].shift(horizon)))\n",
    "    data_prep[horizon] = data_prep[horizon].shift(-horizon)\n",
    "\n",
    "#Drop CLose\n",
    "data_prep.drop(\"Adj Close\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c20dc3c-e59e-4636-92b7-a2c00664b267",
   "metadata": {},
   "source": [
    "### Create test, val, train and prediction data\n",
    "\n",
    "Total length of data is 5530:\n",
    "- Will take half a year - 180 as a test set\n",
    "- Whole year as validation set\n",
    "- Rest as training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3635ab4a-f608-475c-8987-20f2de4c51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 128\n",
    "max_horizon = 5\n",
    "test_size = 360\n",
    "val_size = 360\n",
    "\n",
    "pred_data = data_prep[-128:]\n",
    "\n",
    "#Drop Nans\n",
    "data_prep.dropna(inplace = True)\n",
    "\n",
    "test_data = data_prep[-test_size:]\n",
    "val_data = data_prep[-val_size-test_size:-test_size]\n",
    "train_data = data_prep[:-val_size-test_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185cf53f-8af2-41ae-b349-f293e13bdd19",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a109f2c6-a34e-435b-bce4-a74457d0a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = train_data.mean()\n",
    "train_sd = train_data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5661342d-35ab-4870-b3a1-51975630f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, mean = train_mean, sd = train_sd):\n",
    "    return (data-mean)/sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd0db3ca-c4e4-4261-841f-3f8dfe210649",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = normalize(train_data)\n",
    "val_data = normalize(val_data)\n",
    "test_data = normalize(test_data)\n",
    "pred_data = normalize(pred_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9075c3bf-53d4-44b4-9848-86e5f1264d40",
   "metadata": {},
   "source": [
    "### Apply rolling window and get predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6cf1647-3a10-4fac-8bca-e3dad970cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(data, horizon, window_size = window_size):\n",
    "    data_numpy = np.array(data)\n",
    "    window = sliding_window_view(data_numpy,window_size, axis = 0)\n",
    "    window = np.swapaxes(window, 1,2)\n",
    "    X = window[:,:,0:1]\n",
    "    Y = window[:,:,horizon:horizon+1]\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9161ec8-6663-48a7-951a-03040ef38665",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = convert_data(train_data, horizon = 5)\n",
    "x_val, y_val = convert_data(val_data, horizon = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e964032b-8bd3-42db-a7ee-75f293baa69b",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93b498a0-490e-45ae-97c3-3a7c0e2627b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(trainX, trainY, dropout_rate = 0.15):\n",
    "    \"\"\"\n",
    "    trainX -- input values; shape: [number of samples, NUM_UNROLLINGS, 1]\n",
    "    trainY -- output values (inputs shifted by 1); shape: [number of samples, NUM_UNROLLINGS, 1]\n",
    "    \"\"\"\n",
    "\n",
    "    filters = 8\n",
    "    kernel_size = 2\n",
    "    input_ts = Input(shape=(trainX.shape[1], 1))\n",
    "    #Base layers\n",
    "    x = Conv1D(filters, kernel_size, activation=\"relu\", padding=\"causal\", dilation_rate=1)(input_ts)\n",
    "    x = Conv1D(filters, kernel_size, activation=\"relu\", padding=\"causal\", dilation_rate=2)(x)\n",
    "    x = Conv1D(filters, kernel_size, activation=\"relu\", padding=\"causal\", dilation_rate=4)(x)\n",
    "    x = Conv1D(filters, kernel_size, activation=\"relu\", padding=\"causal\", dilation_rate=8)(x)\n",
    "    x = Conv1D(filters, kernel_size, activation=\"relu\", padding=\"causal\", dilation_rate=16)(x)\n",
    "    x = Conv1D(filters, kernel_size, activation=\"relu\", padding=\"causal\", dilation_rate=32)(x)\n",
    "    #Fully Layer\n",
    "    out = Conv1D(32, 1, padding = \"same\")(x)\n",
    "    out = Dropout(dropout_rate)(out)\n",
    "    out = Conv1D(1, 1, activation=\"linear\")(out)\n",
    "    cnn = Model(input_ts, out)\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d9579-5b62-42bf-9a82-542fbaf3d36a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b7116c-ddb3-4857-b905-2be241831c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 300\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.keras.optimizers.Adadelta(learning_rate = learning_rate)\n",
    "\n",
    "#Early stopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta = 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb89c7-9cfd-4440-88b4-dd210750ae0d",
   "metadata": {},
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b61afa-737a-47b8-9e3d-aaade567cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02baa571-d03f-4f83-bd4e-917fde78bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, x_train, y_train, x_val, y_val, quantile, BATCH_SIZE = BATCH_SIZE, EPOCHS = EPOCHS, callback = callback):\n",
    "    model.compile(optimizer = optimizer,  loss = lambda true,pred: pinball_loss(true, pred, tau = quantile))\n",
    "    history = model.fit(x_train, y_train, validation_data = (x_val, y_val), epochs = EPOCHS,batch_size = BATCH_SIZE, shuffle=True,\n",
    "        callbacks = [callback], verbose = False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b26d8-6e63-4fcc-9e7b-f136283eddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79dbd9-3841-4b02-b5db-2398bc883355",
   "metadata": {},
   "source": [
    "## Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695a869-b5dc-4bcd-abf8-cf50a7551824",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Returns output of shape [samples, enrollings, horizon, quantile]\n",
    "def train_and_predict(train_data = train_data, val_data = val_data, test_data = test_data, pred_data = pred_data, quantiles = quantiles, horizons = horizons):\n",
    "\n",
    "    test_pred = np.zeros((test_size-window_size+1, window_size, len(horizons), len(quantiles)))\n",
    "    future_pred = np.zeros((len(horizons), len(quantiles)))\n",
    "\n",
    "    for horizon in horizons:\n",
    "        #Get data\n",
    "        x_train, y_train = convert_data(train_data, horizon = horizon)\n",
    "        x_val, y_val = convert_data(val_data, horizon = horizon)\n",
    "        x_test, y_test = convert_data(test_data, horizon = horizon)\n",
    "        x_pred, _ = convert_data(pred_data, horizon = horizon)\n",
    "        for cnt, quantile in enumerate(quantiles):           \n",
    "            cnn = model(x_train, y_train)\n",
    "            cnn = train_model(cnn, optimizer, x_train, y_train, x_val, y_val, quantile)\n",
    "\n",
    "            horizon_pred = cnn.predict(x_test)\n",
    "            test_pred[:,:,horizon-1,cnt] = horizon_pred[:,:,0]\n",
    "\n",
    "            #Future pred\n",
    "            future_pred[horizon-1,cnt] = cnn.predict(x_pred)[0,-1,0]\n",
    "            \n",
    "            #Print checkpoint\n",
    "            print(\"Finished horizon_{}, quantile_{}\".format(horizon,quantile))\n",
    "    \n",
    "    #Return predictions\n",
    "    return (test_pred, future_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e8d1e-e720-4622-8e46-b2114a1b0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Returns output of shape [samples, enrollings, horizon, quantile]\n",
    "def train_and_predict(train_data, val_data, pred_data, quantiles = quantiles, horizons = horizons):\n",
    "    \n",
    "    #Get size\n",
    "    pred_size = len(pred_data)\n",
    "\n",
    "    prediction = np.zeros((pred_size-window_size+1, window_size, len(horizons), len(quantiles)))\n",
    "\n",
    "    for horizon in horizons:\n",
    "        #Get data\n",
    "        x_train, y_train = convert_data(train_data, horizon = horizon)\n",
    "        x_val, y_val = convert_data(val_data, horizon = horizon)\n",
    "        x_pred, _ = convert_data(pred_data, horizon = horizon)\n",
    "        for cnt, quantile in enumerate(quantiles):           \n",
    "            cnn = model(x_train, y_train)\n",
    "            cnn = train_model(cnn, optimizer, x_train, y_train, x_val, y_val, quantile)\n",
    "\n",
    "            #Future pred\n",
    "            horizon_pred = cnn.predict(x_pred)\n",
    "            prediction[:,:,horizon-1,cnt] = horizon_pred[:,:,0]\n",
    "            \n",
    "            #Print checkpoint\n",
    "            print(\"Finished horizon_{}, quantile_{}\".format(horizon,quantile))\n",
    "    \n",
    "    #Return predictions\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc1480-fac6-45fe-99da-6a3f2fdfc2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = train_and_predict(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bbc282-c07f-4809-a77a-4c12034cadab",
   "metadata": {},
   "source": [
    "## Analyze results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7beb5658-ee79-4e2e-a5b6-447353cf3896",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b010f93-a1ad-43cb-b505-3fd9c8b7cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_result(data, length = len(test_data)):\n",
    "    results_array = np.zeros((length,5))\n",
    "    for cnt, sample in enumerate(data):\n",
    "        if cnt == 0 :\n",
    "            results_array[0:window_size] = sample[0:window_size]\n",
    "        else :\n",
    "            results_array[window_size+cnt-1] = sample[window_size-1]\n",
    "    return results_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f630d3d-1516-4bb2-98ce-b2e6e649e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, _ = convert_data(test_data, horizon = horizon)\n",
    "##Prepare Loss matrix\n",
    "losses = pd.DataFrame(index = quantiles, columns = horizons)\n",
    "true_transformed = convert_result(x_test, length = len(test_data))\n",
    "for cnt, quantile in enumerate(quantiles):\n",
    "    for horizon in horizons:\n",
    "        pred = test_pred[:,:,horizon-1,cnt:cnt+1]\n",
    "        pred_transformed = convert_result(pred, length = len(test_data))\n",
    "        loss = tf.reduce_mean(pinball_loss(true_transformed[:,horizon-1], pred_transformed[:,horizon-1], tau = quantile))\n",
    "        losses.loc[quantile, horizon] = loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc6b61a-ac28-4ced-a046-4e58cf312b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61c36d-c8d0-4a8c-9412-f314c0768132",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1\n",
    "fig, ax = plt.subplots(figsize=(14,10))\n",
    "true_transformed = convert_result(x_test, length = len(test_data))\n",
    "sns.scatterplot(x = test_data.index, y = true_transformed[:,h-1])\n",
    "for cnt,quantile in enumerate(quantiles):\n",
    "    pred = test_pred[:,:,h-1,cnt:cnt+1]\n",
    "    pred_transformed = convert_result(pred, length = len(test_data))\n",
    "    sns.lineplot(x = test_data.index, y = pred_transformed[:,h-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f336d9c7-66d7-4dd7-9205-0bda10cbaa02",
   "metadata": {},
   "source": [
    "### Test plausability of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d96f6-36ca-469f-b637-2840a0238af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_transformed = convert_result(x_test, length = len(test_data))\n",
    "for cnt, quantile in enumerate(quantiles):\n",
    "    pred = test_pred[:,:,h-1,cnt:cnt+1]\n",
    "    pred_transformed = convert_result(pred, length = len(test_data))\n",
    "    q_smaller = (pred_transformed[:,h-1] > true_transformed[:,h-1]).sum()\n",
    "    emp_quant = q_smaller / pred_transformed[:,h-1].size\n",
    "    print(\"Quantile met for quantile = {}: \\t {} %\".format(quantile, np.round(emp_quant,4)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2109f9fb-cd02-4250-aa31-539a1eebf384",
   "metadata": {},
   "source": [
    "### Loss of baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac9520-d3d6-4640-9ba5-2d6d9277e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(date, days = 1500, data = data_prep):\n",
    "    date = date - timedelta(days)\n",
    "    baseline_results = pd.DataFrame(columns = np.arange(1,6), index = quantiles)\n",
    "    filtered_data = data[data.index < date].iloc[-1000:]\n",
    "\n",
    "    for step in np.arange(1,6):\n",
    "\n",
    "        step_log_return = filtered_data.loc[:,step]\n",
    "        step_log_return.dropna(inplace = True)\n",
    "\n",
    "        #Calculate quantiles\n",
    "        baseline_quantiles = np.quantile(step_log_return, quantiles)\n",
    "        baseline_results.loc[:,step]=baseline_quantiles\n",
    "    return baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41b44a-44e9-4e84-95e8-cb2da714c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(index = quantiles, columns = horizons)\n",
    "losses.loc[:,:] = 0\n",
    "\n",
    "for cnt in range(len(test_data)):\n",
    "    data_sample = test_data.iloc[cnt]\n",
    "    result = get_baseline(data_sample.name)\n",
    "    \n",
    "    for horizon in horizons:\n",
    "        for quantile in quantiles:\n",
    "            pred = result.loc[quantile,horizon]\n",
    "            loss = pinball_loss(data_sample[horizon], pred, quantile).numpy()\n",
    "            losses.loc[quantile,horizon] += loss\n",
    "losses = losses / len(test_data)\n",
    "losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c36b7-31ee-4129-86ca-5099e8f0adb0",
   "metadata": {},
   "source": [
    "## Predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963dcb34-b09a-4680-a5f2-7f8b15c3ba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = train_and_predict(train_data.append(val_data), test_data, pred_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6968e3-db48-4b66-b6e0-672102bbf0b1",
   "metadata": {},
   "source": [
    "### Renormalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7fd75-f450-4778-9d2d-98ebcaafcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract last prediction\n",
    "future_pred = new_pred[0,-1].copy()\n",
    "\n",
    "for i in range(5):\n",
    "    future_pred[i,:] = future_pred[i,:]*train_sd[i+1] + train_mean[i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d325feb0-caab-4a1a-8acd-4efcbe6def5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b2486-be0c-496a-857c-20881ed1b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_horizons = [1,2,5,6,7]\n",
    "final_prediction = pd.DataFrame(columns = [\"forecast_date\",\"target\",\"horizon\",\"q0.025\",\"q0.25\",\"q0.5\",\"q0.75\",\"q0.975\"])\n",
    "final_prediction[\"forecast_date\"] = [(current_day).strftime(\"%Y-%m-%d\") for x in df_horizons]\n",
    "final_prediction[\"horizon\"] = [\"{} day\".format(x) for x in df_horizons]\n",
    "final_prediction[\"target\"] = \"DAX\"\n",
    "\n",
    "for cnt, quantile in enumerate(quantiles):\n",
    "    final_prediction[\"q{}\".format(quantile)] = future_pred[:,cnt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c00a68-461d-4091-b3ed-10ee6f8369c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3cce8f-ca95-4020-bfca-607e106acdb1",
   "metadata": {},
   "source": [
    "## Save final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e668b977-a6ca-4a75-84ab-65e20dc17ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "final_prediction.to_pickle(\"../evaluation/predictions/single/DAX_{}\".format(current_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0347f-1716-4885-8823-7e95680b5629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
