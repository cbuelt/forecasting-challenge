{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "5dcc675b-a528-47d8-817d-66cd81b07b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date, datetime, timedelta\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.math import erf\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import Normalizer,StandardScaler, LabelEncoder\n",
    "from tensorflow_addons.losses import pinball_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "5a9d7181-beab-4222-974f-a5046a47ccc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4510d11-04a6-4c31-a2ec-0b842336dafc",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "3daf8141-c74c-4a94-8c48-d3a39cf41cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data():\n",
    "    \"\"\"\n",
    "    Load data, normalize and get data splits\n",
    "    \"\"\"\n",
    "    data = pd.read_pickle(\"data/complete_data_t_2m\")\n",
    "    data = data[data[\"fcst_hour\"].isin(horizons)]\n",
    "    data_np = data.iloc[:,3:-2].drop(\"obs_tm\", axis = 1).to_numpy()\n",
    "    #Create label encoding for embedding\n",
    "    label_enc = LabelEncoder()\n",
    "    encoding = label_enc.fit_transform(data_np[:,0])\n",
    "    data_np[:,0] = encoding\n",
    "    \n",
    "    Y = data_np[:,1]\n",
    "    X = np.delete(data_np, 1, axis = 1)\n",
    "    train_val_data_X, test_data_X, train_val_data_Y, test_data_Y = train_test_split(X,Y, test_size = 0.1)\n",
    "    train_data_X, val_data_X, train_data_Y,val_data_Y = train_test_split(train_val_data_X,train_val_data_Y, test_size = 0.2)\n",
    "\n",
    "    #Normalize features data based on train set\n",
    "    feature_normalizer = Normalizer()\n",
    "    emb = train_data_X[:,0]\n",
    "    train_data_X = feature_normalizer.fit_transform(train_data_X)\n",
    "    train_data_X[:,0] = emb\n",
    "    \n",
    "    emb = val_data_X[:,0]\n",
    "    val_data_X = feature_normalizer.transform(val_data_X)\n",
    "    val_data_X[:,0] = emb\n",
    "    \n",
    "    emb = test_data_X[:,0]\n",
    "    test_data_X = feature_normalizer.transform(test_data_X)\n",
    "    test_data_X[:,0] = emb\n",
    "    \n",
    "\n",
    "    #Normalize target and save retransform\n",
    "    target_scaler = StandardScaler()\n",
    "    train_data_Y = target_scaler.fit_transform(train_data_Y.reshape(-1,1))\n",
    "    val_data_Y = target_scaler.transform(val_data_Y.reshape(-1,1))\n",
    "    \n",
    "    return train_data_X, train_data_Y, val_data_X, val_data_Y, test_data_X, test_data_Y, feature_normalizer, target_scaler, label_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "bd6c0048-357c-4145-9a03-f78d32d81a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, val_X, val_Y, test_X, test_Y, feature_scaler, target_scaler, label_encoder = get_split_data()\n",
    "no_features = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "72a7bd45-3634-4ef0-9ea6-38c2b9c97c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe6315-fa3a-4000-a2de-7c7714564f6e",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "2c401b24-2bb3-4032-8387-68d8759625eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps_cost_function(y_true, y_pred):\n",
    "    \"\"\"Compute the CRPS cost function for a normal distribution defined by\n",
    "    the mean and standard deviation.\n",
    "    Code inspired by Kai Polsterer (HITS).\n",
    "    Args:\n",
    "        y_true: True values\n",
    "        y_pred: Tensor containing predictions: [mean, std]\n",
    "    Returns:\n",
    "        mean_crps: Scalar with mean CRPS over batch\n",
    "    \"\"\"\n",
    "\n",
    "    # Split input\n",
    "    mu = y_pred[:, 0]\n",
    "    sigma = y_pred[:, 1]\n",
    "    y_true = y_true[:, 0]   # Need to also get rid of axis 1 to match!\n",
    "\n",
    "    # To stop sigma from becoming negative we first have to \n",
    "    # convert it the the variance and then take the square\n",
    "    # root again. \n",
    "    var = K.square(sigma)\n",
    "    # The following three variables are just for convenience\n",
    "    loc = (y_true - mu) / K.sqrt(var)\n",
    "    phi = 1.0 / np.sqrt(2.0 * np.pi) * K.exp(-K.square(loc) / 2.0)\n",
    "    Phi = 0.5 * (1.0 + erf(loc / np.sqrt(2.0)))\n",
    "    # First we will compute the crps for each input/target pair\n",
    "    crps =  K.sqrt(var) * (loc * (2. * Phi - 1.) + 2 * phi - 1. / np.sqrt(np.pi))\n",
    "    # Then we take the mean. The cost is now a scalar\n",
    "    return K.mean(crps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "650ec674-e165-43a9-b763-fe6b866ac6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_model(train_X, train_Y, no_features, n_embeddings = 65, no_outputs = 2):\n",
    "    \"\"\"\n",
    "    trainX -- input values; shape: [number of samples, no_features]\n",
    "    trainY -- output values; shape: [number of samples, 2\n",
    "    \"\"\"    \n",
    "    inp = Input(shape = no_features+1)\n",
    "    #Extract embedding features\n",
    "    horizon = inp[:,0]\n",
    "    features = inp[:,1:]\n",
    "    \n",
    "    #Embedding layer\n",
    "    horizon_emb = Embedding(input_dim = n_embeddings, output_dim = 6)(horizon)\n",
    "    \n",
    "    #Concatenate\n",
    "    conc = Concatenate(axis = 1)([features,horizon_emb])\n",
    "    \n",
    "    #Hidden layer\n",
    "    #hidden = Dense(30, activation = \"relu\")(conc)\n",
    "    \n",
    "    #Linear layer\n",
    "    outputs = Dense(no_outputs, activation = \"linear\")(conc)\n",
    "    model = Model(inputs = inp, outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "b60d1f33-79ac-4881-8b89-c7afb299c20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_34 (InputLayer)           [(None, 41)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_66 (Sl (None,)              0           input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_67 (Sl (None, 40)           0           input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)        (None, 6)            390         tf.__operators__.getitem_66[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 46)           0           tf.__operators__.getitem_67[0][0]\n",
      "                                                                 embedding_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 2)            94          concatenate_33[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 484\n",
      "Trainable params: 484\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = basic_model(train_X, train_Y, no_features)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "4835ea46-5637-496d-97a5-e22b4be0c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_X, train_Y, val_X, val_Y, no_features, batch_size, epochs, learning_rate):\n",
    "    #Define optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    #Early stopping\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta = 1e-5)\n",
    "    #Compile model\n",
    "    model.compile(optimizer = optimizer, loss = crps_cost_function)\n",
    "    model.fit(train_X, train_Y, validation_data = (val_X, val_Y), epochs = EPOCHS, shuffle = True, callbacks = [callback], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "4d5693de-5bd9-4505-8f77-d53e444e144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "bd58e03d-28a3-417e-90e9-55302e6b1d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "115/115 [==============================] - 2s 8ms/step - loss: 0.5862 - val_loss: 0.5041\n",
      "Epoch 2/20\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4890 - val_loss: 0.5037\n",
      "Epoch 3/20\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4923 - val_loss: 0.5070\n",
      "Epoch 4/20\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4845 - val_loss: 0.5049\n",
      "Epoch 5/20\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.4810 - val_loss: 0.5040\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_X, train_Y, val_X, val_Y, no_features, BATCH_SIZE, EPOCHS, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77040432-055d-4329-b3c5-832009a895bc",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "724836a2-5f92-4664-b412-43891791b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get prediction\n",
    "pred = model.predict(test_X)\n",
    "#Retransform\n",
    "pred = target_scaler.inverse_transform(pred)\n",
    "#Square and root results\n",
    "pred[:,1] = np.sqrt(pred[:,1]**2)\n",
    "#Convert prediction to quantiles\n",
    "quantile_pred = np.zeros(shape = (pred.shape[0],5))\n",
    "for cnt,x in enumerate(pred):\n",
    "    quantile_pred[cnt] = norm.ppf(quantiles, loc = x[0], scale = x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24ba71-ee97-4905-a7d1-d7b12b7e6afc",
   "metadata": {},
   "source": [
    "## Evaluate data on realizations with pinball loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "4ed30c23-c19a-4ab9-a2e4-886ae8a7a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 9.553150710019251\n",
      "Pinball loss for quantile 0.25 : \t 4.082893291924755\n",
      "Pinball loss for quantile 0.5 : \t 2.965075153655866\n",
      "Pinball loss for quantile 0.75 : \t 4.053272834190417\n",
      "Pinball loss for quantile 0.975 : \t 9.42747440713632\n"
     ]
    }
   ],
   "source": [
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = pinball_loss(quantile_pred[:,cnt], np.squeeze(test_Y), tau = quantile).numpy()\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06d9e6-501e-4dc9-9774-e2eeb9f3df0d",
   "metadata": {},
   "source": [
    "## Evaluate naive forecast on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "1c292058-fa01-498e-947c-513092bb5be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 12.85571214256123\n",
      "Pinball loss for quantile 0.25 : \t 9.88601912661762\n",
      "Pinball loss for quantile 0.5 : \t 6.606105256502969\n",
      "Pinball loss for quantile 0.75 : \t 3.334102414584358\n",
      "Pinball loss for quantile 0.975 : \t 0.39872598266587644\n"
     ]
    }
   ],
   "source": [
    "naive_pred = np.quantile(test_X[:,1:], quantiles, axis = 1)\n",
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = pinball_loss(naive_pred[cnt], np.squeeze(test_Y), tau = quantile).numpy()\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aa53c3-7838-4d56-b1df-d3bc626bdd52",
   "metadata": {},
   "source": [
    "# Predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "93f538a5-9515-49c2-ad9c-4d4a1094f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [36, 48 ,60, 72, 84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "7d1fd937-e836-484f-9908-e63656c5de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_data(name):\n",
    "    if name == \"temperature\":\n",
    "        method = \"t_2m\"\n",
    "    elif name == \"wind\":\n",
    "        method = \"wind_mean_10m\"\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "        return None\n",
    "    #Set current date\n",
    "    current_date = date.today().strftime(\"%Y%m%d\")\n",
    "    path = \"data/icon_data/icon-eu-eps_{}00_{}_Karlsruhe.txt\".format(current_date, method)\n",
    "    new_data = pd.read_csv(path.format(current_date.replace(\"-\",\"\")), skiprows = 3, sep = \"|\").dropna(axis = 1)\n",
    "    new_data.columns = new_data.columns.str.replace(\" \", \"\")\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "661acb48-8b63-46ac-9ae6-a3fe78746d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_forecast(name, horizons, feature_scaler, label_encoder, model, save = False):\n",
    "    if name == \"temperature\":\n",
    "        method = \"t_2m\"\n",
    "    elif name == \"wind\":\n",
    "        method = \"wind_mean_10m\"\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "        return None\n",
    "    #Get data\n",
    "    data = get_pred_data(name)\n",
    "    data = data[data[\"fcst_hour\"].isin(horizons)].to_numpy()\n",
    "    #Label encoding\n",
    "    encoding = label_encoder.transform(data[:,0])\n",
    "    data[:,0] = encoding\n",
    "    #Normalize\n",
    "    data_pred = feature_scaler.transform(data)\n",
    "    #Predict\n",
    "    pred = model.predict(data_pred)\n",
    "    pred = target_scaler.inverse_transform(pred)\n",
    "    \n",
    "    #Create final prediction dataframe\n",
    "    final_prediction = pd.DataFrame(columns = [\"forecast_date\",\"target\",\"horizon\",\"q0.025\",\"q0.25\",\"q0.5\",\"q0.75\",\"q0.975\"], index = np.arange(0,5))\n",
    "    final_prediction[\"forecast_date\"] = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "    final_prediction[\"horizon\"] = [\"{} hour\".format(x) for x in horizons]\n",
    "    final_prediction[\"target\"] = method\n",
    "    \n",
    "    #Save prediction to dataframe\n",
    "    for cnt,x in enumerate(pred):\n",
    "        final_prediction.loc[final_prediction[\"horizon\"] == \"{} hour\".format(horizons[cnt]), final_prediction.columns[3:]] = (norm.ppf(quantiles, loc = x[0], scale = x[1]))\n",
    "        \n",
    "    #Save prediction\n",
    "    if save == True:\n",
    "        final_prediction.to_pickle(\"../evaluation/predictions/single/{}_{}\".format(name, date.today().strftime(\"%Y-%m-%d\")))\n",
    "    \n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "6f21ff9e-c155-44cb-83a4-cf729a688a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>target</th>\n",
       "      <th>horizon</th>\n",
       "      <th>q0.025</th>\n",
       "      <th>q0.25</th>\n",
       "      <th>q0.5</th>\n",
       "      <th>q0.75</th>\n",
       "      <th>q0.975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>36 hour</td>\n",
       "      <td>9.37708</td>\n",
       "      <td>13.533568</td>\n",
       "      <td>15.714482</td>\n",
       "      <td>17.895396</td>\n",
       "      <td>22.051885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>48 hour</td>\n",
       "      <td>9.165731</td>\n",
       "      <td>13.284482</td>\n",
       "      <td>15.445595</td>\n",
       "      <td>17.606708</td>\n",
       "      <td>21.725459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>60 hour</td>\n",
       "      <td>9.386095</td>\n",
       "      <td>13.553684</td>\n",
       "      <td>15.740422</td>\n",
       "      <td>17.927161</td>\n",
       "      <td>22.09475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>72 hour</td>\n",
       "      <td>9.122155</td>\n",
       "      <td>13.357952</td>\n",
       "      <td>15.58048</td>\n",
       "      <td>17.803007</td>\n",
       "      <td>22.038804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>84 hour</td>\n",
       "      <td>9.340326</td>\n",
       "      <td>13.535341</td>\n",
       "      <td>15.736469</td>\n",
       "      <td>17.937598</td>\n",
       "      <td>22.132612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  forecast_date target  horizon    q0.025      q0.25       q0.5      q0.75  \\\n",
       "0    2021-10-25   t_2m  36 hour   9.37708  13.533568  15.714482  17.895396   \n",
       "1    2021-10-25   t_2m  48 hour  9.165731  13.284482  15.445595  17.606708   \n",
       "2    2021-10-25   t_2m  60 hour  9.386095  13.553684  15.740422  17.927161   \n",
       "3    2021-10-25   t_2m  72 hour  9.122155  13.357952   15.58048  17.803007   \n",
       "4    2021-10-25   t_2m  84 hour  9.340326  13.535341  15.736469  17.937598   \n",
       "\n",
       "      q0.975  \n",
       "0  22.051885  \n",
       "1  21.725459  \n",
       "2   22.09475  \n",
       "3  22.038804  \n",
       "4  22.132612  "
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_final_forecast(\"temperature\",horizons, feature_scaler, label_encoder, model, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6167c5-1ee3-4b5f-9d2d-5645f801ff73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
