{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5dcc675b-a528-47d8-817d-66cd81b07b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date, datetime, timedelta\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.math import erf\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import Normalizer,StandardScaler\n",
    "from tensorflow_addons.losses import pinball_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9d7181-beab-4222-974f-a5046a47ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.1\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4510d11-04a6-4c31-a2ec-0b842336dafc",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "3daf8141-c74c-4a94-8c48-d3a39cf41cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data():\n",
    "    \"\"\"\n",
    "    Load data, normalize and get data splits\n",
    "    \"\"\"\n",
    "    data = pd.read_pickle(\"data/complete_data_t_2m\")\n",
    "    data_np = data.iloc[:,3:-2].drop(\"obs_tm\", axis = 1).to_numpy()\n",
    "    Y = data_np[:,1]\n",
    "    X = np.delete(data_np, 1, axis = 1)\n",
    "    train_val_data_X, test_data_X, train_val_data_Y, test_data_Y = train_test_split(X,Y, test_size = 0.1)\n",
    "    train_data_X, val_data_X, train_data_Y,val_data_Y = train_test_split(train_val_data_X,train_val_data_Y, test_size = 0.2)\n",
    "\n",
    "    #Normalize features data based on train set\n",
    "    feature_normalizer = Normalizer()\n",
    "    train_data_X = feature_normalizer.fit_transform(train_data_X)\n",
    "    val_data_X = feature_normalizer.transform(val_data_X)\n",
    "    test_data_X = feature_normalizer.transform(test_data_X)\n",
    "\n",
    "    #Normalize target and save retransform\n",
    "    target_scaler = StandardScaler()\n",
    "    train_data_Y = target_scaler.fit_transform(train_data_Y.reshape(-1,1))\n",
    "    val_data_Y = target_scaler.transform(val_data_Y.reshape(-1,1))\n",
    "    \n",
    "    return train_data_X, train_data_Y, val_data_X, val_data_Y, test_data_X, test_data_Y, feature_normalizer, target_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "bd6c0048-357c-4145-9a03-f78d32d81a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, val_X, val_Y, test_X, test_Y, feature_scaler, target_scaler = get_split_data()\n",
    "no_features = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "72a7bd45-3634-4ef0-9ea6-38c2b9c97c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe6315-fa3a-4000-a2de-7c7714564f6e",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "2c401b24-2bb3-4032-8387-68d8759625eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps_cost_function(y_true, y_pred):\n",
    "    \"\"\"Compute the CRPS cost function for a normal distribution defined by\n",
    "    the mean and standard deviation.\n",
    "    Code inspired by Kai Polsterer (HITS).\n",
    "    Args:\n",
    "        y_true: True values\n",
    "        y_pred: Tensor containing predictions: [mean, std]\n",
    "    Returns:\n",
    "        mean_crps: Scalar with mean CRPS over batch\n",
    "    \"\"\"\n",
    "\n",
    "    # Split input\n",
    "    mu = y_pred[:, 0]\n",
    "    sigma = y_pred[:, 1]\n",
    "    y_true = y_true[:, 0]   # Need to also get rid of axis 1 to match!\n",
    "\n",
    "    # To stop sigma from becoming negative we first have to \n",
    "    # convert it the the variance and then take the square\n",
    "    # root again. \n",
    "    var = K.square(sigma)\n",
    "    # The following three variables are just for convenience\n",
    "    loc = (y_true - mu) / K.sqrt(var)\n",
    "    phi = 1.0 / np.sqrt(2.0 * np.pi) * K.exp(-K.square(loc) / 2.0)\n",
    "    Phi = 0.5 * (1.0 + erf(loc / np.sqrt(2.0)))\n",
    "    # First we will compute the crps for each input/target pair\n",
    "    crps =  K.sqrt(var) * (loc * (2. * Phi - 1.) + 2 * phi - 1. / np.sqrt(np.pi))\n",
    "    # Then we take the mean. The cost is now a scalar\n",
    "    return K.mean(crps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "650ec674-e165-43a9-b763-fe6b866ac6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_model(train_X, train_Y, no_features, n_embeddings = 65, no_outputs = 2):\n",
    "    \"\"\"\n",
    "    trainX -- input values; shape: [number of samples, no_features]\n",
    "    trainY -- output values; shape: [number of samples, 2\n",
    "    \"\"\"    \n",
    "    inp = Input(shape = no_features+1)\n",
    "    #Extract embedding features\n",
    "    horizon = inp[:,0]\n",
    "    features = inp[:,1:]\n",
    "    \n",
    "    #Embedding layer\n",
    "    horizon_emb = Embedding(input_dim = n_embeddings, output_dim = 4)(horizon)\n",
    "    \n",
    "    #Concatenate\n",
    "    conc = Concatenate(axis = 1)([features,horizon_emb])\n",
    "    \n",
    "    #Linear layer\n",
    "    outputs = Dense(no_outputs, activation = \"linear\")(conc)\n",
    "    model = Model(inputs = inp, outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "b60d1f33-79ac-4881-8b89-c7afb299c20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           [(None, 41)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_42 (Sl (None,)              0           input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_43 (Sl (None, 40)           0           input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 4)            260         tf.__operators__.getitem_42[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 44)           0           tf.__operators__.getitem_43[0][0]\n",
      "                                                                 embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 2)            90          concatenate_21[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 350\n",
      "Trainable params: 350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = basic_model(train_X, train_Y, no_features)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "4d5693de-5bd9-4505-8f77-d53e444e144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "\n",
    "#Early stopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, min_delta = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "bd58e03d-28a3-417e-90e9-55302e6b1d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "model.compile(optimizer = optimizer, loss = crps_cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "fdf0d768-6e93-4d2b-8443-b66df4bb2b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "115/115 [==============================] - 1s 6ms/step - loss: 0.3272 - val_loss: 0.3305\n",
      "Epoch 2/10\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3268 - val_loss: 0.3279\n",
      "Epoch 3/10\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3276 - val_loss: 0.3295\n",
      "Epoch 4/10\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3271 - val_loss: 0.3280\n",
      "Epoch 5/10\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3269 - val_loss: 0.3333\n",
      "Epoch 6/10\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3260 - val_loss: 0.3321\n",
      "Epoch 7/10\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.3266 - val_loss: 0.3290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x160168d11c0>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y, validation_data = (val_X, val_Y), epochs = EPOCHS, shuffle = True, callbacks = [callback], verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77040432-055d-4329-b3c5-832009a895bc",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "724836a2-5f92-4664-b412-43891791b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get prediction\n",
    "pred = model.predict(test_X)\n",
    "#Retransform\n",
    "pred = target_scaler.inverse_transform(pred)\n",
    "#Square and root results\n",
    "pred[:,1] = np.sqrt(pred[:,1]**2)\n",
    "#Convert prediction to quantiles\n",
    "quantile_pred = np.zeros(shape = (pred.shape[0],5))\n",
    "for cnt,x in enumerate(pred):\n",
    "    quantile_pred[cnt] = norm.ppf(quantiles, loc = x[0], scale = x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24ba71-ee97-4905-a7d1-d7b12b7e6afc",
   "metadata": {},
   "source": [
    "## Evaluate data on realizations with pinball loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "4ed30c23-c19a-4ab9-a2e4-886ae8a7a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 34.85618806044823\n",
      "Pinball loss for quantile 0.25 : \t 9.323556179734924\n",
      "Pinball loss for quantile 0.5 : \t 1.765189041542072\n",
      "Pinball loss for quantile 0.75 : \t 9.060524149481232\n",
      "Pinball loss for quantile 0.975 : \t 34.47369501229695\n"
     ]
    }
   ],
   "source": [
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = pinball_loss(quantile_pred[:,cnt], np.squeeze(test_Y), tau = quantile).numpy()\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06d9e6-501e-4dc9-9774-e2eeb9f3df0d",
   "metadata": {},
   "source": [
    "## Evaluate naive forecast on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "1c292058-fa01-498e-947c-513092bb5be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 11.728580052158545\n",
      "Pinball loss for quantile 0.25 : \t 9.041139497832699\n",
      "Pinball loss for quantile 0.5 : \t 6.0656028602783225\n",
      "Pinball loss for quantile 0.75 : \t 3.0941338855338274\n",
      "Pinball loss for quantile 0.975 : \t 0.42383174183491606\n"
     ]
    }
   ],
   "source": [
    "naive_pred = np.quantile(test_X[:,1:], quantiles, axis = 1)\n",
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = pinball_loss(naive_pred[cnt], np.squeeze(test_Y), tau = quantile).numpy()\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aa53c3-7838-4d56-b1df-d3bc626bdd52",
   "metadata": {},
   "source": [
    "# Predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "93f538a5-9515-49c2-ad9c-4d4a1094f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [36, 48 ,60, 72, 84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "7d1fd937-e836-484f-9908-e63656c5de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_data(name):\n",
    "    if name == \"temperature\":\n",
    "        method = \"t_2m\"\n",
    "    elif name == \"wind\":\n",
    "        method = \"wind_mean_10m\"\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "        return None\n",
    "    #Set current date\n",
    "    current_date = date.today().strftime(\"%Y%m%d\")\n",
    "    path = \"data/icon_data/icon-eu-eps_{}00_{}_Karlsruhe.txt\".format(current_date, method)\n",
    "    new_data = pd.read_csv(path.format(current_date.replace(\"-\",\"\")), skiprows = 3, sep = \"|\").dropna(axis = 1)\n",
    "    new_data.columns = new_data.columns.str.replace(\" \", \"\")\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "661acb48-8b63-46ac-9ae6-a3fe78746d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_forecast(name, horizons, feature_scaler, model):\n",
    "    if name == \"temperature\":\n",
    "        method = \"t_2m\"\n",
    "    elif name == \"wind\":\n",
    "        method = \"wind_mean_10m\"\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "        return None\n",
    "    #Get data\n",
    "    data = get_pred_data(name)\n",
    "    data = data[data[\"fcst_hour\"].isin(horizons)].to_numpy()\n",
    "    #Normalize\n",
    "    data_pred = feature_scaler.transform(data)\n",
    "    #Predict\n",
    "    pred = model.predict(data_pred)\n",
    "    pred = target_scaler.inverse_transform(pred)\n",
    "    \n",
    "    #Create final prediction dataframe\n",
    "    final_prediction = pd.DataFrame(columns = [\"forecast_date\",\"target\",\"horizon\",\"q0.025\",\"q0.25\",\"q0.5\",\"q0.75\",\"q0.975\"], index = np.arange(0,5))\n",
    "    final_prediction[\"forecast_date\"] = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "    final_prediction[\"horizon\"] = [\"{} hour\".format(x) for x in horizons]\n",
    "    final_prediction[\"target\"] = method\n",
    "    \n",
    "    #Save prediction to dataframe\n",
    "    for cnt,x in enumerate(pred):\n",
    "        final_prediction.loc[final_prediction[\"horizon\"] == \"{} hour\".format(horizons[cnt]), final_prediction.columns[3:]] = (norm.ppf(quantiles, loc = x[0], scale = x[1]))\n",
    "    \n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "6f21ff9e-c155-44cb-83a4-cf729a688a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>target</th>\n",
       "      <th>horizon</th>\n",
       "      <th>q0.025</th>\n",
       "      <th>q0.25</th>\n",
       "      <th>q0.5</th>\n",
       "      <th>q0.75</th>\n",
       "      <th>q0.975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>36 hour</td>\n",
       "      <td>-19.305566</td>\n",
       "      <td>5.182126</td>\n",
       "      <td>18.030846</td>\n",
       "      <td>30.879565</td>\n",
       "      <td>55.367257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>48 hour</td>\n",
       "      <td>-24.228226</td>\n",
       "      <td>-1.15943</td>\n",
       "      <td>10.944793</td>\n",
       "      <td>23.049015</td>\n",
       "      <td>46.117811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>60 hour</td>\n",
       "      <td>-21.260019</td>\n",
       "      <td>2.867767</td>\n",
       "      <td>15.527642</td>\n",
       "      <td>28.187518</td>\n",
       "      <td>52.315304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>72 hour</td>\n",
       "      <td>-27.270948</td>\n",
       "      <td>-4.69987</td>\n",
       "      <td>7.1432</td>\n",
       "      <td>18.98627</td>\n",
       "      <td>41.557348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-25</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>84 hour</td>\n",
       "      <td>-23.162582</td>\n",
       "      <td>0.283384</td>\n",
       "      <td>12.585508</td>\n",
       "      <td>24.887633</td>\n",
       "      <td>48.333599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  forecast_date target  horizon     q0.025     q0.25       q0.5      q0.75  \\\n",
       "0    2021-10-25   t_2m  36 hour -19.305566  5.182126  18.030846  30.879565   \n",
       "1    2021-10-25   t_2m  48 hour -24.228226  -1.15943  10.944793  23.049015   \n",
       "2    2021-10-25   t_2m  60 hour -21.260019  2.867767  15.527642  28.187518   \n",
       "3    2021-10-25   t_2m  72 hour -27.270948  -4.69987     7.1432   18.98627   \n",
       "4    2021-10-25   t_2m  84 hour -23.162582  0.283384  12.585508  24.887633   \n",
       "\n",
       "      q0.975  \n",
       "0  55.367257  \n",
       "1  46.117811  \n",
       "2  52.315304  \n",
       "3  41.557348  \n",
       "4  48.333599  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_final_forecast(\"temperature\",horizons, feature_scaler, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c2ac3-6332-4b83-ba7b-64ebec1b2de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
