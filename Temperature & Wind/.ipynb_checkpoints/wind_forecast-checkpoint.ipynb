{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "95c87b87-6742-42a5-a360-caf0067f0a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date, datetime, timedelta\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.math import erf\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import Normalizer,StandardScaler, LabelEncoder\n",
    "from tensorflow_addons.losses import pinball_loss\n",
    "from tensorflow_lattice.layers import Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b058c-cc23-4ea4-8879-2fa0d4454cc4",
   "metadata": {},
   "source": [
    "# Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d46b04-690f-4c5e-9826-865a90030282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>init_tm</th>\n",
       "      <th>met_var</th>\n",
       "      <th>location</th>\n",
       "      <th>fcst_hour</th>\n",
       "      <th>obs_tm</th>\n",
       "      <th>obs</th>\n",
       "      <th>ens_1</th>\n",
       "      <th>ens_2</th>\n",
       "      <th>ens_3</th>\n",
       "      <th>ens_4</th>\n",
       "      <th>...</th>\n",
       "      <th>ens_33</th>\n",
       "      <th>ens_34</th>\n",
       "      <th>ens_35</th>\n",
       "      <th>ens_36</th>\n",
       "      <th>ens_37</th>\n",
       "      <th>ens_38</th>\n",
       "      <th>ens_39</th>\n",
       "      <th>ens_40</th>\n",
       "      <th>ens_mean</th>\n",
       "      <th>ens_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.80</td>\n",
       "      <td>6.56</td>\n",
       "      <td>4.54</td>\n",
       "      <td>5.05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.59</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.47</td>\n",
       "      <td>5.99</td>\n",
       "      <td>3.48</td>\n",
       "      <td>4.92</td>\n",
       "      <td>5.09</td>\n",
       "      <td>4.58675</td>\n",
       "      <td>0.565448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-12-18 01:00:00+00:00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.68</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.33</td>\n",
       "      <td>...</td>\n",
       "      <td>4.92</td>\n",
       "      <td>5.18</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.88</td>\n",
       "      <td>6.39</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.18</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.69750</td>\n",
       "      <td>0.663747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-12-18 02:00:00+00:00</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.28</td>\n",
       "      <td>7.10</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.44</td>\n",
       "      <td>...</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.88</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.80</td>\n",
       "      <td>6.66</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.81650</td>\n",
       "      <td>0.830100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018-12-18 03:00:00+00:00</td>\n",
       "      <td>5.04</td>\n",
       "      <td>3.47</td>\n",
       "      <td>7.45</td>\n",
       "      <td>6.11</td>\n",
       "      <td>5.66</td>\n",
       "      <td>...</td>\n",
       "      <td>5.37</td>\n",
       "      <td>4.58</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.86</td>\n",
       "      <td>6.96</td>\n",
       "      <td>4.41</td>\n",
       "      <td>5.26</td>\n",
       "      <td>4.74</td>\n",
       "      <td>5.01625</td>\n",
       "      <td>1.222111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-12-18 04:00:00+00:00</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.56</td>\n",
       "      <td>8.02</td>\n",
       "      <td>6.29</td>\n",
       "      <td>5.81</td>\n",
       "      <td>...</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.05</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.26</td>\n",
       "      <td>6.67</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.56</td>\n",
       "      <td>5.01600</td>\n",
       "      <td>1.355050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    init_tm   met_var location  fcst_hour  \\\n",
       "0 2018-12-18 00:00:00+00:00  wind_10m   Berlin        0.0   \n",
       "1 2018-12-18 00:00:00+00:00  wind_10m   Berlin        1.0   \n",
       "2 2018-12-18 00:00:00+00:00  wind_10m   Berlin        2.0   \n",
       "3 2018-12-18 00:00:00+00:00  wind_10m   Berlin        3.0   \n",
       "4 2018-12-18 00:00:00+00:00  wind_10m   Berlin        4.0   \n",
       "\n",
       "                     obs_tm   obs  ens_1  ens_2  ens_3  ens_4  ...  ens_33  \\\n",
       "0 2018-12-18 00:00:00+00:00  6.48   3.80   6.56   4.54   5.05  ...    5.59   \n",
       "1 2018-12-18 01:00:00+00:00  6.12   3.68   7.03   5.06   5.33  ...    4.92   \n",
       "2 2018-12-18 02:00:00+00:00  4.32   3.28   7.10   5.39   5.44  ...    4.91   \n",
       "3 2018-12-18 03:00:00+00:00  5.04   3.47   7.45   6.11   5.66  ...    5.37   \n",
       "4 2018-12-18 04:00:00+00:00  6.48   3.56   8.02   6.29   5.81  ...    5.30   \n",
       "\n",
       "   ens_34  ens_35  ens_36  ens_37  ens_38  ens_39  ens_40  ens_mean   ens_var  \n",
       "0    5.45    5.30    4.47    5.99    3.48    4.92    5.09   4.58675  0.565448  \n",
       "1    5.18    4.98    4.88    6.39    3.74    5.18    4.85   4.69750  0.663747  \n",
       "2    4.88    5.20    4.80    6.66    4.14    5.05    4.80   4.81650  0.830100  \n",
       "3    4.58    5.30    4.86    6.96    4.41    5.26    4.74   5.01625  1.222111  \n",
       "4    4.05    5.04    5.26    6.67    4.86    4.95    4.56   5.01600  1.355050  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_feather(\"data/berlin_data/historic_data/icon_eps_wind_10m.feather\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a19e40d-ed9a-4508-b580-f5fd8400e0e7",
   "metadata": {},
   "source": [
    "## Dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23761223-4f12-49bb-afc0-937bdce54e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2d08ca-65d2-42fd-a4eb-bd4f1f32d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "hour = data[\"fcst_hour\"]\n",
    "data = data.iloc[:,3:-2].drop(\"obs_tm\", axis = 1)\n",
    "data = (data - data.mean())/data.std()\n",
    "data[\"fcst_hour\"] = hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237e1b46-e69e-415a-b2f1-ad21741b2d55",
   "metadata": {},
   "source": [
    "## Convert data to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50375fda-ab7a-4ff0-a89a-315936b8c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346d990b-14a5-4e01-b4a6-bb47b3ecc747",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc = LabelEncoder()\n",
    "encoding = label_enc.fit_transform(data_np[:,0])\n",
    "data_np[:,0] = encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b102af7-0f3f-4a64-a4a9-5ca473ece0e7",
   "metadata": {},
   "source": [
    "## Train, val, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e235d099-c210-4ffd-8f05-ded00a446025",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(data_np, test_size = 0.1)\n",
    "train, val = train_test_split(train_val, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ba78957c-9346-45cf-bfe3-6fd950b6e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_format(input_data):\n",
    "    #Extract forecast embedding\n",
    "    horizon_emb = input_data[:,0]\n",
    "    # Extract target\n",
    "    target = np.expand_dims(input_data[:,1],1)\n",
    "    #Extract features\n",
    "    features = input_data[:,2:]\n",
    "    \n",
    "    return [features, horizon_emb], target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "f64c0313-aaba-4927-b7e0-c028ef2871de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = convert_format(train)\n",
    "val_data, val_target = convert_format(val)\n",
    "test_data, test_target = convert_format(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f9a31-842f-4af8-9e5e-65938d9aa29c",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "6330b732-4945-4fee-928d-68ce05bc9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "427ab472-e25f-4453-85e6-b2b6d58ced77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class base_model(tf.keras.Model):    \n",
    "    def __init__(self, no_features, n_embeddings = 65):\n",
    "        super(base_model, self).__init__()\n",
    "        #Embedding layers\n",
    "        self.embedding = Embedding(input_dim = n_embeddings, output_dim = 4)\n",
    "        #Create Dense layers\n",
    "        self.hidden = Dense(25, activation = \"relu\")\n",
    "        self.out = Dense(1, activation = \"linear\")\n",
    "        #Define monotonicites\n",
    "        #mono = list(np.append(np.zeros(25),1))\n",
    "        #self.linear = Linear(num_input_dims = 26, units = 1, monotonicities = mono, use_bias = True)\n",
    "\n",
    "    def call(self, input_data):\n",
    "        #Extract data\n",
    "        features, horizon_emb = input_data\n",
    "        #Calculate embedding\n",
    "        emb = self.embedding(horizon_emb)\n",
    "        emb = tf.squeeze(emb, axis = 1)\n",
    "        conc = Concatenate(axis = 1)([features, emb])\n",
    "        #Calculate output\n",
    "        output = self.hidden(conc)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "dcaff8bb-e0fc-4ca2-8f81-8d702e18fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = base_model(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "b7f81e25-a90a-48c9-9357-2e46377b020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "036a2cb0-6d6d-47f9-81b7-fe4ca725cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "#Compile model\n",
    "test_model.compile(optimizer = optimizer, loss = lambda true,pred: pinball_loss(true, pred, tau = 0.975))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "a77703a2-0e8f-4254-afdd-dfa1f61d9d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "180/180 [==============================] - 1s 5ms/step - loss: 0.1044 - val_loss: 0.0446\n",
      "Epoch 2/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0413 - val_loss: 0.0411\n",
      "Epoch 3/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0398 - val_loss: 0.0408\n",
      "Epoch 4/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0392 - val_loss: 0.0405\n",
      "Epoch 5/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0383 - val_loss: 0.0405\n",
      "Epoch 6/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0383 - val_loss: 0.0409\n",
      "Epoch 7/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0382 - val_loss: 0.0409\n",
      "Epoch 8/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0383 - val_loss: 0.0405\n",
      "Epoch 9/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0379 - val_loss: 0.0403\n",
      "Epoch 10/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0376 - val_loss: 0.0410\n",
      "Epoch 11/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0378 - val_loss: 0.0403\n",
      "Epoch 12/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0375 - val_loss: 0.0400\n",
      "Epoch 13/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0376 - val_loss: 0.0409\n",
      "Epoch 14/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0369 - val_loss: 0.0409\n",
      "Epoch 15/15\n",
      "180/180 [==============================] - 1s 4ms/step - loss: 0.0368 - val_loss: 0.0408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14e88133310>"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.fit(x = train_data, y = train_target, validation_data = (val_data, val_target), epochs = EPOCHS, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "b03885ae-158a-4ba8-844e-b0142b37c7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"base_model_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     multiple                  260       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             multiple                  1125      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             multiple                  26        \n",
      "=================================================================\n",
      "Total params: 1,411\n",
      "Trainable params: 1,411\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b654dc1-0fad-4efa-a1b2-7555e6a901e1",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "cf866306-0355-4f3f-813b-50e8ffcf2553",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = test_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e9db2-9a20-48f2-a977-e6ccff02f431",
   "metadata": {},
   "source": [
    "## Evaluate pinball loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "ead8f99c-60e7-45a6-a3fd-aaaea5dfc4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.042199276>"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinball_loss(np.squeeze(test_target), np.squeeze(pred), tau = 0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "e4326918-88d5-4b0f-843d-11c2eda9b968",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt,quantile in enumerate(quantiles):\n",
    "    break\n",
    "    pred_filtered = pred[pred[:,1]==quantile]\n",
    "    test_filtered = test_target[pred[:,1]==quantile,0:1]\n",
    "    loss = np.mean(pinball_loss(test_filtered,pred_filtered, tau = quantile).numpy())\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa09f86-cb04-4800-9728-857028132e40",
   "metadata": {},
   "source": [
    "## Evaluate pinball loss on naive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "177ddcf0-93b9-46d3-b18f-fa43960f4f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 0.061658888239079127\n",
      "Pinball loss for quantile 0.25 : \t 0.19784392141286428\n",
      "Pinball loss for quantile 0.5 : \t 0.24384083580018143\n",
      "Pinball loss for quantile 0.75 : \t 0.20890743961319938\n",
      "Pinball loss for quantile 0.975 : \t 0.07647236849793138\n"
     ]
    }
   ],
   "source": [
    "naive_pred = np.quantile(test_data[0], quantiles, axis = 1)\n",
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = pinball_loss(np.squeeze(test_target), naive_pred[cnt], tau = quantile).numpy()\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d783c6-3f85-4823-ad89-88dfbd54e954",
   "metadata": {},
   "source": [
    "# Predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b98f1-3cdf-4064-9fbc-5869905049ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
