{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c87b87-6742-42a5-a360-caf0067f0a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date, datetime, timedelta\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.math import erf\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import Normalizer,StandardScaler, LabelEncoder\n",
    "from tensorflow_addons.losses import pinball_loss\n",
    "from tensorflow_lattice.layers import Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b058c-cc23-4ea4-8879-2fa0d4454cc4",
   "metadata": {},
   "source": [
    "# Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d46b04-690f-4c5e-9826-865a90030282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>init_tm</th>\n",
       "      <th>met_var</th>\n",
       "      <th>location</th>\n",
       "      <th>fcst_hour</th>\n",
       "      <th>obs_tm</th>\n",
       "      <th>obs</th>\n",
       "      <th>ens_1</th>\n",
       "      <th>ens_2</th>\n",
       "      <th>ens_3</th>\n",
       "      <th>ens_4</th>\n",
       "      <th>...</th>\n",
       "      <th>ens_33</th>\n",
       "      <th>ens_34</th>\n",
       "      <th>ens_35</th>\n",
       "      <th>ens_36</th>\n",
       "      <th>ens_37</th>\n",
       "      <th>ens_38</th>\n",
       "      <th>ens_39</th>\n",
       "      <th>ens_40</th>\n",
       "      <th>ens_mean</th>\n",
       "      <th>ens_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.80</td>\n",
       "      <td>6.56</td>\n",
       "      <td>4.54</td>\n",
       "      <td>5.05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.59</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.47</td>\n",
       "      <td>5.99</td>\n",
       "      <td>3.48</td>\n",
       "      <td>4.92</td>\n",
       "      <td>5.09</td>\n",
       "      <td>4.58675</td>\n",
       "      <td>0.565448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-12-18 01:00:00+00:00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.68</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.33</td>\n",
       "      <td>...</td>\n",
       "      <td>4.92</td>\n",
       "      <td>5.18</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.88</td>\n",
       "      <td>6.39</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.18</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.69750</td>\n",
       "      <td>0.663747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-12-18 02:00:00+00:00</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.28</td>\n",
       "      <td>7.10</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.44</td>\n",
       "      <td>...</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.88</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.80</td>\n",
       "      <td>6.66</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.81650</td>\n",
       "      <td>0.830100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018-12-18 03:00:00+00:00</td>\n",
       "      <td>5.04</td>\n",
       "      <td>3.47</td>\n",
       "      <td>7.45</td>\n",
       "      <td>6.11</td>\n",
       "      <td>5.66</td>\n",
       "      <td>...</td>\n",
       "      <td>5.37</td>\n",
       "      <td>4.58</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.86</td>\n",
       "      <td>6.96</td>\n",
       "      <td>4.41</td>\n",
       "      <td>5.26</td>\n",
       "      <td>4.74</td>\n",
       "      <td>5.01625</td>\n",
       "      <td>1.222111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-12-18 04:00:00+00:00</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.56</td>\n",
       "      <td>8.02</td>\n",
       "      <td>6.29</td>\n",
       "      <td>5.81</td>\n",
       "      <td>...</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.05</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.26</td>\n",
       "      <td>6.67</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.56</td>\n",
       "      <td>5.01600</td>\n",
       "      <td>1.355050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    init_tm   met_var location  fcst_hour  \\\n",
       "0 2018-12-18 00:00:00+00:00  wind_10m   Berlin        0.0   \n",
       "1 2018-12-18 00:00:00+00:00  wind_10m   Berlin        1.0   \n",
       "2 2018-12-18 00:00:00+00:00  wind_10m   Berlin        2.0   \n",
       "3 2018-12-18 00:00:00+00:00  wind_10m   Berlin        3.0   \n",
       "4 2018-12-18 00:00:00+00:00  wind_10m   Berlin        4.0   \n",
       "\n",
       "                     obs_tm   obs  ens_1  ens_2  ens_3  ens_4  ...  ens_33  \\\n",
       "0 2018-12-18 00:00:00+00:00  6.48   3.80   6.56   4.54   5.05  ...    5.59   \n",
       "1 2018-12-18 01:00:00+00:00  6.12   3.68   7.03   5.06   5.33  ...    4.92   \n",
       "2 2018-12-18 02:00:00+00:00  4.32   3.28   7.10   5.39   5.44  ...    4.91   \n",
       "3 2018-12-18 03:00:00+00:00  5.04   3.47   7.45   6.11   5.66  ...    5.37   \n",
       "4 2018-12-18 04:00:00+00:00  6.48   3.56   8.02   6.29   5.81  ...    5.30   \n",
       "\n",
       "   ens_34  ens_35  ens_36  ens_37  ens_38  ens_39  ens_40  ens_mean   ens_var  \n",
       "0    5.45    5.30    4.47    5.99    3.48    4.92    5.09   4.58675  0.565448  \n",
       "1    5.18    4.98    4.88    6.39    3.74    5.18    4.85   4.69750  0.663747  \n",
       "2    4.88    5.20    4.80    6.66    4.14    5.05    4.80   4.81650  0.830100  \n",
       "3    4.58    5.30    4.86    6.96    4.41    5.26    4.74   5.01625  1.222111  \n",
       "4    4.05    5.04    5.26    6.67    4.86    4.95    4.56   5.01600  1.355050  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_feather(\"data/berlin_data/historic_data/icon_eps_wind_10m.feather\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a19e40d-ed9a-4508-b580-f5fd8400e0e7",
   "metadata": {},
   "source": [
    "## Dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23761223-4f12-49bb-afc0-937bdce54e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2d08ca-65d2-42fd-a4eb-bd4f1f32d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "hour = data[\"fcst_hour\"]\n",
    "data = data.iloc[:,3:-2].drop(\"obs_tm\", axis = 1)\n",
    "data[\"fcst_hour\"] = hour\n",
    "data_np = data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b102af7-0f3f-4a64-a4a9-5ca473ece0e7",
   "metadata": {},
   "source": [
    "## Train, val, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e235d099-c210-4ffd-8f05-ded00a446025",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(data_np, test_size = 0.1)\n",
    "train, val = train_test_split(train_val, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d7426d-03b3-45db-89db-c30902fb7655",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b72e22d-2362-4c63-a868-8c373b12890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, feature_scaler = None, target_scaler = None, learn = False):\n",
    "    if learn == True:\n",
    "        feature_scaler = StandardScaler()\n",
    "        target_scaler = StandardScaler()\n",
    "        #Learn target scaling\n",
    "        target_scaled = target_scaler.fit_transform(data[:,1].reshape(-1,1))\n",
    "        #Learn feature scaling\n",
    "        feature_scaled = feature_scaler.fit_transform(data[:,2:])\n",
    "        #Append\n",
    "        data[:,1] = target_scaled.reshape(-1)\n",
    "        data[:,2:] = feature_scaled\n",
    "        \n",
    "        return data, feature_scaler, target_scaler\n",
    "    \n",
    "    else:\n",
    "        #Scale target\n",
    "        target_scaled = target_scaler.transform(data[:,1].reshape(-1,1))\n",
    "        #Scale features\n",
    "        feature_scaled = feature_scaler.transform(data[:,2:])\n",
    "        #Append\n",
    "        data[:,1] = target_scaled.reshape(-1)\n",
    "        data[:,2:] = feature_scaled\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e886bd-d209-4638-b8dc-2200bf8d96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, feature_scaler, target_scaler = normalize(train, learn = True)\n",
    "train_val = normalize(train_val, feature_scaler, target_scaler)\n",
    "test = normalize(test, feature_scaler, target_scaler)\n",
    "val = normalize(val, feature_scaler, target_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba78957c-9346-45cf-bfe3-6fd950b6e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_format(input_data, predict = False):\n",
    "    #Extract forecast embedding\n",
    "    horizon_emb = input_data[:,0]\n",
    "    \n",
    "    if predict == False:        \n",
    "        #Extract features\n",
    "        features = input_data[:,2:]\n",
    "        # Extract target\n",
    "        target = np.expand_dims(input_data[:,1],1)\n",
    "        return [features, horizon_emb], target\n",
    "    else:\n",
    "        #Extract features\n",
    "        features = input_data[:,1:]\n",
    "        return [features, horizon_emb]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f64c0313-aaba-4927-b7e0-c028ef2871de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = convert_format(train)\n",
    "val_data, val_target = convert_format(val)\n",
    "test_data, test_target = convert_format(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f9a31-842f-4af8-9e5e-65938d9aa29c",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6330b732-4945-4fee-928d-68ce05bc9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 50\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "427ab472-e25f-4453-85e6-b2b6d58ced77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class base_model(tf.keras.Model):    \n",
    "    def __init__(self, no_features = 40, n_embeddings = 121):\n",
    "        super(base_model, self).__init__()\n",
    "        #Embedding layers\n",
    "        self.embedding = Embedding(input_dim = n_embeddings, output_dim = 4)\n",
    "        #Create Dense layers\n",
    "        self.hidden = Dense(25, activation = \"relu\")\n",
    "        self.out = Dense(1, activation = \"linear\")\n",
    "\n",
    "    def call(self, input_data):\n",
    "        #Extract data\n",
    "        features, horizon_emb = input_data\n",
    "        #Calculate embedding\n",
    "        emb = self.embedding(horizon_emb)\n",
    "        emb = tf.squeeze(emb, axis = 1)\n",
    "        conc = Concatenate(axis = 1)([features, emb])\n",
    "        #Calculate output\n",
    "        output = self.hidden(conc)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b4d25cb-4755-48e8-a7fd-347750d86b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, quantile, train_data, train_target, validation_data, batch_size, epochs, learning_rate):\n",
    "    #Define optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    #Early stopping\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5, min_delta = 1e-5)\n",
    "    #Compile model\n",
    "    model.compile(optimizer = optimizer, loss = lambda true,pred: pinball_loss(true, pred, tau = quantile))\n",
    "    model.fit(x = train_data, y = train_target, validation_data = validation_data, epochs = epochs, batch_size = batch_size, callbacks = [callback], shuffle = True, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4887da3d-afaf-42dd-b6b6-b9bf47dfbfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_models(train_data, train_target, validation_data, batch_size = BATCH_SIZE, epochs = EPOCHS, learning_rate = learning_rate, quantiles = quantiles):\n",
    "    models = []\n",
    "    for quantile in quantiles:\n",
    "        model = base_model()\n",
    "        train_model(model, quantile, train_data, train_target, validation_data, batch_size, epochs, learning_rate)\n",
    "        print(\"Training finished for quantile: {}\".format(quantile))\n",
    "        models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e329a18-d85e-4f3f-908d-136deefda713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for quantile: 0.025\n",
      "Training finished for quantile: 0.25\n",
      "Training finished for quantile: 0.5\n",
      "Training finished for quantile: 0.75\n",
      "Training finished for quantile: 0.975\n"
     ]
    }
   ],
   "source": [
    "trained_models = create_all_models(train_data, train_target, (val_data, val_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b654dc1-0fad-4efa-a1b2-7555e6a901e1",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e9db2-9a20-48f2-a977-e6ccff02f431",
   "metadata": {},
   "source": [
    "## Evaluate pinball loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ead8f99c-60e7-45a6-a3fd-aaaea5dfc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for cnt,_ in enumerate(quantiles):\n",
    "    pred = trained_models[cnt].predict(test_data)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "633d0669-31d8-4edc-be3a-d3cce8bae007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 0.030550554394721985\n",
      "Pinball loss for quantile 0.25 : \t 0.17490561306476593\n",
      "Pinball loss for quantile 0.5 : \t 0.22989022731781006\n",
      "Pinball loss for quantile 0.75 : \t 0.19356249272823334\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pinball_loss at 0x000001BD178C0E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Pinball loss for quantile 0.975 : \t 0.03985196352005005\n"
     ]
    }
   ],
   "source": [
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = pinball_loss(test_target.reshape(-1), predictions[cnt].reshape(-1), tau = quantile).numpy()\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa09f86-cb04-4800-9728-857028132e40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate pinball loss on naive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b851be17-c49d-4e57-a717-1ac1ce11924a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function pinball_loss at 0x000001BD178C0E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Pinball loss for quantile 0.025 : \t 0.06182668176195165\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function pinball_loss at 0x000001BD178C0E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Pinball loss for quantile 0.25 : \t 0.19513981675276262\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function pinball_loss at 0x000001BD178C0E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Pinball loss for quantile 0.5 : \t 0.23807509441740377\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function pinball_loss at 0x000001BD178C0E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Pinball loss for quantile 0.75 : \t 0.20293556067357782\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function pinball_loss at 0x000001BD178C0E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Pinball loss for quantile 0.975 : \t 0.07250960824050695\n"
     ]
    }
   ],
   "source": [
    "naive_pred = np.quantile(test_data[0], quantiles, axis = 1)\n",
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = pinball_loss(np.squeeze(test_target), naive_pred[cnt], tau = quantile).numpy()\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d783c6-3f85-4823-ad89-88dfbd54e954",
   "metadata": {},
   "source": [
    "# Predict new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d822308c-2d0b-4fb6-9874-f9dba32d4668",
   "metadata": {},
   "source": [
    "## Train on complete data without test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5d0d281-5cd3-43bc-97e3-1b3495246f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = convert_format(train_val)\n",
    "val_data, val_target = convert_format(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f76d614f-64cf-4def-819f-f6cec92f3e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for quantile: 0.025\n",
      "Training finished for quantile: 0.25\n",
      "Training finished for quantile: 0.5\n",
      "Training finished for quantile: 0.75\n",
      "Training finished for quantile: 0.975\n"
     ]
    }
   ],
   "source": [
    "trained_models = create_all_models(train_data, train_target, (val_data, val_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e586b-40b4-47dd-8052-86281866f51a",
   "metadata": {},
   "source": [
    "## Predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "158257ae-528c-4877-be09-ab3b74783a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [36, 48 ,60, 72, 84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f2a45c8-da64-4fde-9446-3280324a6018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set current date\n",
    "current_date = date.today().strftime(\"%Y%m%d\")\n",
    "path = \"data/berlin_data/icon_data/icon-eu-eps_{}00_wind_mean_10m_Berlin.txt\".format(current_date)\n",
    "new_data = pd.read_csv(path.format(current_date.replace(\"-\",\"\")), skiprows = 3, sep = \"|\").dropna(axis = 1)\n",
    "new_data.columns = new_data.columns.str.replace(\" \", \"\")\n",
    "# Normalize and get horizons\n",
    "new_data = new_data[new_data[\"fcst_hour\"].isin(horizons)].to_numpy()\n",
    "new_data[:,1:] = feature_scaler.transform(new_data[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15935e68-3d66-4718-891d-c07b28dddb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = convert_format(new_data, predict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbc89af2-ff03-4ee4-a1e0-62fbd5d7998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare dataframe\n",
    "final_prediction = pd.DataFrame(columns = [\"forecast_date\",\"target\",\"horizon\",\"q0.025\",\"q0.25\",\"q0.5\",\"q0.75\",\"q0.975\"], index = np.arange(0,5))\n",
    "final_prediction[\"forecast_date\"] = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "final_prediction[\"horizon\"] = [\"{} hour\".format(x) for x in horizons]\n",
    "final_prediction[\"target\"] = \"wind\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f8bcdbe-043d-4e3d-b7e6-fd5ae42a6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt, quantile in enumerate(quantiles):\n",
    "    #Get prediction\n",
    "    prediction = trained_models[cnt].predict(pred_data)\n",
    "    #Retransform\n",
    "    final_pred = target_scaler.inverse_transform(prediction)\n",
    "    final_prediction.loc[:,\"q{}\".format(quantile)] = final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a12ec3ef-a08b-4962-850f-5882ed486b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>target</th>\n",
       "      <th>horizon</th>\n",
       "      <th>q0.025</th>\n",
       "      <th>q0.25</th>\n",
       "      <th>q0.5</th>\n",
       "      <th>q0.75</th>\n",
       "      <th>q0.975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>wind</td>\n",
       "      <td>36 hour</td>\n",
       "      <td>9.008980</td>\n",
       "      <td>14.112084</td>\n",
       "      <td>17.420645</td>\n",
       "      <td>20.307768</td>\n",
       "      <td>25.082108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>wind</td>\n",
       "      <td>48 hour</td>\n",
       "      <td>8.901674</td>\n",
       "      <td>14.817027</td>\n",
       "      <td>17.945885</td>\n",
       "      <td>21.549999</td>\n",
       "      <td>28.956566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>wind</td>\n",
       "      <td>60 hour</td>\n",
       "      <td>9.045424</td>\n",
       "      <td>13.840762</td>\n",
       "      <td>16.221087</td>\n",
       "      <td>18.463316</td>\n",
       "      <td>23.152771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>wind</td>\n",
       "      <td>72 hour</td>\n",
       "      <td>7.066521</td>\n",
       "      <td>12.672591</td>\n",
       "      <td>14.257113</td>\n",
       "      <td>17.415918</td>\n",
       "      <td>25.860399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>wind</td>\n",
       "      <td>84 hour</td>\n",
       "      <td>10.816050</td>\n",
       "      <td>15.574940</td>\n",
       "      <td>19.018330</td>\n",
       "      <td>21.133451</td>\n",
       "      <td>26.780411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  forecast_date target  horizon     q0.025      q0.25       q0.5      q0.75  \\\n",
       "0    2021-11-03   wind  36 hour   9.008980  14.112084  17.420645  20.307768   \n",
       "1    2021-11-03   wind  48 hour   8.901674  14.817027  17.945885  21.549999   \n",
       "2    2021-11-03   wind  60 hour   9.045424  13.840762  16.221087  18.463316   \n",
       "3    2021-11-03   wind  72 hour   7.066521  12.672591  14.257113  17.415918   \n",
       "4    2021-11-03   wind  84 hour  10.816050  15.574940  19.018330  21.133451   \n",
       "\n",
       "      q0.975  \n",
       "0  25.082108  \n",
       "1  28.956566  \n",
       "2  23.152771  \n",
       "3  25.860399  \n",
       "4  26.780411  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5cb1ee4-677a-4e33-9ec9-8b72640e3806",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction.to_pickle(\"../evaluation/predictions/single/{}_{}\".format(\"wind\", date.today().strftime(\"%Y-%m-%d\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f3642c-a831-4858-b2f8-131ebb0a1f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
