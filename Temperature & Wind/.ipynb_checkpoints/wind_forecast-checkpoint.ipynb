{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c87b87-6742-42a5-a360-caf0067f0a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date, datetime, timedelta\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import Normalizer,StandardScaler, LabelEncoder\n",
    "from tensorflow_addons.losses import pinball_loss\n",
    "from sklearn.metrics import mean_pinball_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b058c-cc23-4ea4-8879-2fa0d4454cc4",
   "metadata": {},
   "source": [
    "# Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d46b04-690f-4c5e-9826-865a90030282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>init_tm</th>\n",
       "      <th>met_var</th>\n",
       "      <th>location</th>\n",
       "      <th>fcst_hour</th>\n",
       "      <th>obs_tm</th>\n",
       "      <th>obs</th>\n",
       "      <th>ens_1</th>\n",
       "      <th>ens_2</th>\n",
       "      <th>ens_3</th>\n",
       "      <th>ens_4</th>\n",
       "      <th>...</th>\n",
       "      <th>ens_33</th>\n",
       "      <th>ens_34</th>\n",
       "      <th>ens_35</th>\n",
       "      <th>ens_36</th>\n",
       "      <th>ens_37</th>\n",
       "      <th>ens_38</th>\n",
       "      <th>ens_39</th>\n",
       "      <th>ens_40</th>\n",
       "      <th>ens_mean</th>\n",
       "      <th>ens_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.80</td>\n",
       "      <td>6.56</td>\n",
       "      <td>4.54</td>\n",
       "      <td>5.05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.59</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.47</td>\n",
       "      <td>5.99</td>\n",
       "      <td>3.48</td>\n",
       "      <td>4.92</td>\n",
       "      <td>5.09</td>\n",
       "      <td>4.58675</td>\n",
       "      <td>0.565448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-12-18 01:00:00+00:00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.68</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.33</td>\n",
       "      <td>...</td>\n",
       "      <td>4.92</td>\n",
       "      <td>5.18</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.88</td>\n",
       "      <td>6.39</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.18</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.69750</td>\n",
       "      <td>0.663747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-12-18 02:00:00+00:00</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.28</td>\n",
       "      <td>7.10</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.44</td>\n",
       "      <td>...</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.88</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.80</td>\n",
       "      <td>6.66</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.81650</td>\n",
       "      <td>0.830100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018-12-18 03:00:00+00:00</td>\n",
       "      <td>5.04</td>\n",
       "      <td>3.47</td>\n",
       "      <td>7.45</td>\n",
       "      <td>6.11</td>\n",
       "      <td>5.66</td>\n",
       "      <td>...</td>\n",
       "      <td>5.37</td>\n",
       "      <td>4.58</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.86</td>\n",
       "      <td>6.96</td>\n",
       "      <td>4.41</td>\n",
       "      <td>5.26</td>\n",
       "      <td>4.74</td>\n",
       "      <td>5.01625</td>\n",
       "      <td>1.222111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-12-18 04:00:00+00:00</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.56</td>\n",
       "      <td>8.02</td>\n",
       "      <td>6.29</td>\n",
       "      <td>5.81</td>\n",
       "      <td>...</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.05</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.26</td>\n",
       "      <td>6.67</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.56</td>\n",
       "      <td>5.01600</td>\n",
       "      <td>1.355050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    init_tm   met_var location  fcst_hour  \\\n",
       "0 2018-12-18 00:00:00+00:00  wind_10m   Berlin        0.0   \n",
       "1 2018-12-18 00:00:00+00:00  wind_10m   Berlin        1.0   \n",
       "2 2018-12-18 00:00:00+00:00  wind_10m   Berlin        2.0   \n",
       "3 2018-12-18 00:00:00+00:00  wind_10m   Berlin        3.0   \n",
       "4 2018-12-18 00:00:00+00:00  wind_10m   Berlin        4.0   \n",
       "\n",
       "                     obs_tm   obs  ens_1  ens_2  ens_3  ens_4  ...  ens_33  \\\n",
       "0 2018-12-18 00:00:00+00:00  6.48   3.80   6.56   4.54   5.05  ...    5.59   \n",
       "1 2018-12-18 01:00:00+00:00  6.12   3.68   7.03   5.06   5.33  ...    4.92   \n",
       "2 2018-12-18 02:00:00+00:00  4.32   3.28   7.10   5.39   5.44  ...    4.91   \n",
       "3 2018-12-18 03:00:00+00:00  5.04   3.47   7.45   6.11   5.66  ...    5.37   \n",
       "4 2018-12-18 04:00:00+00:00  6.48   3.56   8.02   6.29   5.81  ...    5.30   \n",
       "\n",
       "   ens_34  ens_35  ens_36  ens_37  ens_38  ens_39  ens_40  ens_mean   ens_var  \n",
       "0    5.45    5.30    4.47    5.99    3.48    4.92    5.09   4.58675  0.565448  \n",
       "1    5.18    4.98    4.88    6.39    3.74    5.18    4.85   4.69750  0.663747  \n",
       "2    4.88    5.20    4.80    6.66    4.14    5.05    4.80   4.81650  0.830100  \n",
       "3    4.58    5.30    4.86    6.96    4.41    5.26    4.74   5.01625  1.222111  \n",
       "4    4.05    5.04    5.26    6.67    4.86    4.95    4.56   5.01600  1.355050  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_feather(\"data/berlin_data/historic_data/icon_eps_wind_10m.feather\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a61ef2-6979-4c75-b699-8ab25c8b97cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "horizons = [36, 48 ,60, 72, 84]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4b5481-eb7e-49ca-afec-58682f55ec56",
   "metadata": {},
   "source": [
    "## Change data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d44c2a-f067-4510-b9be-7c75f028330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    data_prep = data.dropna().copy()\n",
    "    data_prep.drop([\"init_tm\", \"met_var\", \"location\", \"ens_mean\", \"ens_var\", \"obs_tm\"], axis = 1, inplace = True)\n",
    "    return data_prep.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f126faa5-7653-40c0-8747-891f31410285",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = prepare_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b102af7-0f3f-4a64-a4a9-5ca473ece0e7",
   "metadata": {},
   "source": [
    "## Train, val, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e235d099-c210-4ffd-8f05-ded00a446025",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(data_np, test_size = 0.2)\n",
    "train, val = train_test_split(train_val, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d7426d-03b3-45db-89db-c30902fb7655",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b72e22d-2362-4c63-a868-8c373b12890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, feature_scaler = None, target_scaler = None, learn = False):\n",
    "    if learn == True:\n",
    "        feature_scaler = StandardScaler()\n",
    "        target_scaler = StandardScaler()\n",
    "        #Learn target scaling\n",
    "        target_scaled = target_scaler.fit_transform(data[:,1].reshape(-1,1))\n",
    "        #Learn feature scaling\n",
    "        feature_scaled = feature_scaler.fit_transform(data[:,2:])\n",
    "        #Append\n",
    "        data[:,1] = target_scaled.reshape(-1)\n",
    "        data[:,2:] = feature_scaled\n",
    "        \n",
    "        return data, feature_scaler, target_scaler\n",
    "    \n",
    "    else:\n",
    "        #Scale target\n",
    "        target_scaled = target_scaler.transform(data[:,1].reshape(-1,1))\n",
    "        #Scale features\n",
    "        feature_scaled = feature_scaler.transform(data[:,2:])\n",
    "        #Append\n",
    "        data[:,1] = target_scaled.reshape(-1)\n",
    "        data[:,2:] = feature_scaled\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e886bd-d209-4638-b8dc-2200bf8d96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, feature_scaler, target_scaler = normalize(train, learn = True)\n",
    "train_val = normalize(train_val, feature_scaler, target_scaler)\n",
    "test = normalize(test, feature_scaler, target_scaler)\n",
    "val = normalize(val, feature_scaler, target_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba78957c-9346-45cf-bfe3-6fd950b6e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_format(input_data, predict = False):\n",
    "    #Extract forecast embedding\n",
    "    horizon_emb = input_data[:,0]\n",
    "    \n",
    "    if predict == False:        \n",
    "        #Extract features\n",
    "        features = input_data[:,2:]\n",
    "        # Extract target\n",
    "        target = np.expand_dims(input_data[:,1],1)\n",
    "        return [features, horizon_emb], target\n",
    "    else:\n",
    "        #Extract features\n",
    "        features = input_data[:,1:]\n",
    "        return [features, horizon_emb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f64c0313-aaba-4927-b7e0-c028ef2871de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = convert_format(train)\n",
    "val_data, val_target = convert_format(val)\n",
    "test_data, test_target = convert_format(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f9a31-842f-4af8-9e5e-65938d9aa29c",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6330b732-4945-4fee-928d-68ce05bc9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "EPOCHS = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "427ab472-e25f-4453-85e6-b2b6d58ced77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class base_model(tf.keras.Model):    \n",
    "    def __init__(self, n_embeddings = 121):\n",
    "        super(base_model, self).__init__()\n",
    "        #Embedding layers\n",
    "        self.embedding = Embedding(input_dim = n_embeddings, output_dim = 4)\n",
    "        #Create Dense layers\n",
    "        self.hidden = Dense(25, activation = \"relu\")\n",
    "        self.out = Dense(1, activation = \"linear\")\n",
    "\n",
    "    def call(self, input_data):\n",
    "        #Extract data\n",
    "        features, horizon_emb = input_data\n",
    "        #Calculate embedding\n",
    "        emb = self.embedding(horizon_emb)\n",
    "        emb = tf.squeeze(emb, axis = 1)\n",
    "        conc = Concatenate(axis = 1)([features, emb])\n",
    "        #Calculate output\n",
    "        output = self.hidden(conc)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b4d25cb-4755-48e8-a7fd-347750d86b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, quantile, train_data, train_target, validation_data, batch_size, epochs, learning_rate):\n",
    "    #Define optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    #Early stopping\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5, min_delta = 1e-5)\n",
    "    #Compile model\n",
    "    model.compile(optimizer = optimizer, loss = lambda true,pred: pinball_loss(true, pred, tau = quantile))\n",
    "    model.fit(x = train_data, y = train_target, validation_data = validation_data, epochs = epochs, batch_size = batch_size, callbacks = [callback], shuffle = True, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4887da3d-afaf-42dd-b6b6-b9bf47dfbfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_models(train_data, train_target, validation_data, batch_size = BATCH_SIZE, epochs = EPOCHS, learning_rate = learning_rate, quantiles = quantiles):\n",
    "    models = []\n",
    "    for quantile in quantiles:\n",
    "        model = base_model()\n",
    "        train_model(model, quantile, train_data, train_target, validation_data, batch_size, epochs, learning_rate)\n",
    "        print(\"Training finished for quantile: {}\".format(quantile))\n",
    "        models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e329a18-d85e-4f3f-908d-136deefda713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for quantile: 0.025\n",
      "Training finished for quantile: 0.25\n",
      "Training finished for quantile: 0.5\n",
      "Training finished for quantile: 0.75\n",
      "Training finished for quantile: 0.975\n"
     ]
    }
   ],
   "source": [
    "trained_models = create_all_models(train_data, train_target, (val_data, val_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b654dc1-0fad-4efa-a1b2-7555e6a901e1",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e9db2-9a20-48f2-a977-e6ccff02f431",
   "metadata": {},
   "source": [
    "## Evaluate pinball loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ead8f99c-60e7-45a6-a3fd-aaaea5dfc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for cnt,_ in enumerate(quantiles):\n",
    "    pred = trained_models[cnt].predict(test_data)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "633d0669-31d8-4edc-be3a-d3cce8bae007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 0.03090684728392412\n",
      "Pinball loss for quantile 0.25 : \t 0.17571710239060787\n",
      "Pinball loss for quantile 0.5 : \t 0.2306377417838152\n",
      "Pinball loss for quantile 0.75 : \t 0.19388537190455185\n",
      "Pinball loss for quantile 0.975 : \t 0.040970405790303664\n"
     ]
    }
   ],
   "source": [
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = mean_pinball_loss(test_target.reshape(-1), predictions[cnt].reshape(-1), alpha = quantile)\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa09f86-cb04-4800-9728-857028132e40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate pinball loss on naive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b851be17-c49d-4e57-a717-1ac1ce11924a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 0.06462032497724328\n",
      "Pinball loss for quantile 0.25 : \t 0.19556289228571738\n",
      "Pinball loss for quantile 0.5 : \t 0.2374278109825133\n",
      "Pinball loss for quantile 0.75 : \t 0.20309419632532472\n",
      "Pinball loss for quantile 0.975 : \t 0.073521968776437\n"
     ]
    }
   ],
   "source": [
    "naive_pred = np.quantile(test_data[0], quantiles, axis = 1)\n",
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = mean_pinball_loss(np.squeeze(test_target), naive_pred[cnt], alpha = quantile)\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c2145-f06a-442b-8b86-93bb13424025",
   "metadata": {},
   "source": [
    "## Check plausability of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40555fc2-d96c-4a92-a0d5-1f87e42470f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile met for quantile = 0.025: \t 3.36 %\n",
      "Quantile met for quantile = 0.25: \t 23.799999999999997 %\n",
      "Quantile met for quantile = 0.5: \t 52.25 %\n",
      "Quantile met for quantile = 0.75: \t 75.26 %\n",
      "Quantile met for quantile = 0.975: \t 95.87 %\n"
     ]
    }
   ],
   "source": [
    "for cnt,pred in enumerate(predictions):\n",
    "    q_smaller = (pred > test_target).sum()\n",
    "    emp_quant = q_smaller / pred.size\n",
    "    print(\"Quantile met for quantile = {}: \\t {} %\".format(quantiles[cnt], np.round(emp_quant,4)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d783c6-3f85-4823-ad89-88dfbd54e954",
   "metadata": {},
   "source": [
    "# Predict new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d822308c-2d0b-4fb6-9874-f9dba32d4668",
   "metadata": {},
   "source": [
    "## Train on complete data without test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5d0d281-5cd3-43bc-97e3-1b3495246f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = convert_format(train_val)\n",
    "val_data, val_target = convert_format(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f76d614f-64cf-4def-819f-f6cec92f3e6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18988/2193528710.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrained_models\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_all_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18988/632806609.py\u001b[0m in \u001b[0;36mcreate_all_models\u001b[1;34m(train_data, train_target, validation_data, batch_size, epochs, learning_rate, quantiles)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mquantile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquantiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquantile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training finished for quantile: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18988/165036794.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, quantile, train_data, train_target, validation_data, batch_size, epochs, learning_rate)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#Compile model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mtrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpinball_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquantile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_models = create_all_models(train_data, train_target, (val_data, val_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e586b-40b4-47dd-8052-86281866f51a",
   "metadata": {},
   "source": [
    "## Predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a45c8-da64-4fde-9446-3280324a6018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set current date\n",
    "current_date = date.today().strftime(\"%Y%m%d\")\n",
    "path = \"data/berlin_data/icon_data/icon-eu-eps_{}00_wind_mean_10m_Berlin.txt\".format(current_date)\n",
    "new_data = pd.read_csv(path.format(current_date.replace(\"-\",\"\")), skiprows = 3, sep = \"|\").dropna(axis = 1)\n",
    "new_data.columns = new_data.columns.str.replace(\" \", \"\")\n",
    "# Normalize and get horizons\n",
    "new_data = new_data[new_data[\"fcst_hour\"].isin(horizons)].to_numpy()\n",
    "new_data[:,1:] = feature_scaler.transform(new_data[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15935e68-3d66-4718-891d-c07b28dddb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = convert_format(new_data, predict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc89af2-ff03-4ee4-a1e0-62fbd5d7998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare dataframe\n",
    "final_prediction = pd.DataFrame(columns = [\"forecast_date\",\"target\",\"horizon\",\"q0.025\",\"q0.25\",\"q0.5\",\"q0.75\",\"q0.975\"], index = np.arange(0,5))\n",
    "final_prediction[\"forecast_date\"] = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "final_prediction[\"horizon\"] = [\"{} hour\".format(x) for x in horizons]\n",
    "final_prediction[\"target\"] = \"wind\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8bcdbe-043d-4e3d-b7e6-fd5ae42a6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cnt, quantile in enumerate(quantiles):\n",
    "    #Get prediction\n",
    "    prediction = trained_models[cnt].predict(pred_data)\n",
    "    #Retransform\n",
    "    final_pred = target_scaler.inverse_transform(prediction)\n",
    "    final_prediction.loc[:,\"q{}\".format(quantile)] = final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ec3ef-a08b-4962-850f-5882ed486b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40dc3ca-e8f4-4e7c-a32e-af2aa2cc998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv(path.format(current_date.replace(\"-\",\"\")), skiprows = 3, sep = \"|\").dropna(axis = 1)\n",
    "new_data.columns = new_data.columns.str.replace(\" \", \"\")\n",
    "new_data[new_data[\"fcst_hour\"].isin(horizons)].quantile(0.5, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb1ee4-677a-4e33-9ec9-8b72640e3806",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction.to_pickle(\"../evaluation/predictions/single/{}_{}\".format(\"wind\", date.today().strftime(\"%Y-%m-%d\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f3642c-a831-4858-b2f8-131ebb0a1f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
