{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dcc675b-a528-47d8-817d-66cd81b07b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date, datetime, timedelta\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import Normalizer,StandardScaler, LabelEncoder\n",
    "from tensorflow_addons.losses import pinball_loss\n",
    "from sklearn.metrics import mean_pinball_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72a7bd45-3634-4ef0-9ea6-38c2b9c97c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "horizons = [36, 48 ,60, 72, 84]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4510d11-04a6-4c31-a2ec-0b842336dafc",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33903f39-2172-42bf-8827-7ec99afc0f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>init_tm</th>\n",
       "      <th>met_var</th>\n",
       "      <th>location</th>\n",
       "      <th>fcst_hour</th>\n",
       "      <th>obs_tm</th>\n",
       "      <th>obs</th>\n",
       "      <th>ens_1</th>\n",
       "      <th>ens_2</th>\n",
       "      <th>ens_3</th>\n",
       "      <th>ens_4</th>\n",
       "      <th>...</th>\n",
       "      <th>ens_33</th>\n",
       "      <th>ens_34</th>\n",
       "      <th>ens_35</th>\n",
       "      <th>ens_36</th>\n",
       "      <th>ens_37</th>\n",
       "      <th>ens_38</th>\n",
       "      <th>ens_39</th>\n",
       "      <th>ens_40</th>\n",
       "      <th>ens_mean</th>\n",
       "      <th>ens_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-13 00:00:00+00:00</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-12-13 00:00:00+00:00</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.61</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.34500</td>\n",
       "      <td>0.148036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-13 00:00:00+00:00</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-12-13 01:00:00+00:00</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.30125</td>\n",
       "      <td>0.162580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-13 00:00:00+00:00</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-12-13 02:00:00+00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.32525</td>\n",
       "      <td>0.171626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-13 00:00:00+00:00</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018-12-13 03:00:00+00:00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.31700</td>\n",
       "      <td>0.161878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-13 00:00:00+00:00</td>\n",
       "      <td>t_2m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-12-13 04:00:00+00:00</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.29275</td>\n",
       "      <td>0.150544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    init_tm met_var location  fcst_hour  \\\n",
       "0 2018-12-13 00:00:00+00:00    t_2m   Berlin        0.0   \n",
       "1 2018-12-13 00:00:00+00:00    t_2m   Berlin        1.0   \n",
       "2 2018-12-13 00:00:00+00:00    t_2m   Berlin        2.0   \n",
       "3 2018-12-13 00:00:00+00:00    t_2m   Berlin        3.0   \n",
       "4 2018-12-13 00:00:00+00:00    t_2m   Berlin        4.0   \n",
       "\n",
       "                     obs_tm  obs  ens_1  ens_2  ens_3  ens_4  ...  ens_33  \\\n",
       "0 2018-12-13 00:00:00+00:00  2.3   0.05   0.03   0.32   0.61  ...    0.30   \n",
       "1 2018-12-13 01:00:00+00:00  2.3   0.06   0.00   0.34   0.51  ...    0.13   \n",
       "2 2018-12-13 02:00:00+00:00  2.2   0.10   0.11   0.40   0.45  ...    0.08   \n",
       "3 2018-12-13 03:00:00+00:00  2.2   0.12   0.32   0.48   0.42  ...    0.05   \n",
       "4 2018-12-13 04:00:00+00:00  2.1   0.11   0.57   0.54   0.35  ...    0.03   \n",
       "\n",
       "   ens_34  ens_35  ens_36  ens_37  ens_38  ens_39  ens_40  ens_mean   ens_var  \n",
       "0   -0.03    0.44    0.42    0.05    0.47    0.51    0.74   0.34500  0.148036  \n",
       "1    0.05    0.39    0.38    0.04    0.38    0.33    0.60   0.30125  0.162580  \n",
       "2    0.15    0.57    0.37    0.08    0.42    0.31    0.57   0.32525  0.171626  \n",
       "3    0.19    0.68    0.32    0.08    0.28    0.35    0.60   0.31700  0.161878  \n",
       "4    0.17    0.76    0.30    0.10    0.11    0.34    0.56   0.29275  0.150544  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_feather(\"data/berlin_data/historic_data/icon_eps_t_2m.feather\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3daf8141-c74c-4a94-8c48-d3a39cf41cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    data_prep = data.dropna().copy()\n",
    "    data_prep.drop([\"init_tm\", \"met_var\", \"location\", \"ens_mean\", \"ens_var\", \"obs_tm\"], axis = 1, inplace = True)\n",
    "    return data_prep.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6259e9f7-b645-41d5-a3db-7f6f3970a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = prepare_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3556da-7ec8-4619-93f2-a911db38f0db",
   "metadata": {},
   "source": [
    "## Train, val, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd6c0048-357c-4145-9a03-f78d32d81a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(data_np, test_size = 0.2)\n",
    "train, val = train_test_split(train_val, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dca02c-d2f6-4e83-b68b-a0f78e15466d",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19dee4e5-8eba-4f60-a4ad-75d930725ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, feature_scaler = None, target_scaler = None, learn = False):\n",
    "    if learn == True:\n",
    "        feature_scaler = StandardScaler()\n",
    "        target_scaler = StandardScaler()\n",
    "        #Learn target scaling\n",
    "        target_scaled = target_scaler.fit_transform(data[:,1].reshape(-1,1))\n",
    "        #Learn feature scaling\n",
    "        feature_scaled = feature_scaler.fit_transform(data[:,2:])\n",
    "        #Append\n",
    "        data[:,1] = target_scaled.reshape(-1)\n",
    "        data[:,2:] = feature_scaled\n",
    "        \n",
    "        return data, feature_scaler, target_scaler\n",
    "    \n",
    "    else:\n",
    "        #Scale target\n",
    "        target_scaled = target_scaler.transform(data[:,1].reshape(-1,1))\n",
    "        #Scale features\n",
    "        feature_scaled = feature_scaler.transform(data[:,2:])\n",
    "        #Append\n",
    "        data[:,1] = target_scaled.reshape(-1)\n",
    "        data[:,2:] = feature_scaled\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bab981b-fa00-4102-9f15-a7b9b6baf764",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, feature_scaler, target_scaler = normalize(train, learn = True)\n",
    "train_val = normalize(train_val, feature_scaler, target_scaler)\n",
    "test = normalize(test, feature_scaler, target_scaler)\n",
    "val = normalize(val, feature_scaler, target_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e91ce055-b236-4060-926a-36fa33dea304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_format(input_data, predict = False):\n",
    "    #Extract forecast embedding\n",
    "    horizon_emb = input_data[:,0]\n",
    "    \n",
    "    if predict == False:        \n",
    "        #Extract features\n",
    "        features = input_data[:,2:]\n",
    "        # Extract target\n",
    "        target = np.expand_dims(input_data[:,1],1)\n",
    "        return [features, horizon_emb], target\n",
    "    else:\n",
    "        #Extract features\n",
    "        features = input_data[:,1:]\n",
    "        return [features, horizon_emb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55bd7ffb-df12-420f-80f7-cab75ab53795",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = convert_format(train)\n",
    "val_data, val_target = convert_format(val)\n",
    "test_data, test_target = convert_format(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe6315-fa3a-4000-a2de-7c7714564f6e",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c401b24-2bb3-4032-8387-68d8759625eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "EPOCHS = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "650ec674-e165-43a9-b763-fe6b866ac6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class base_model(tf.keras.Model):    \n",
    "    def __init__(self, n_embeddings = 121):\n",
    "        super(base_model, self).__init__()\n",
    "        #Embedding layers\n",
    "        self.embedding = Embedding(input_dim = n_embeddings, output_dim = 4)\n",
    "        #Create Dense layers\n",
    "        self.hidden = Dense(25, activation = \"relu\")\n",
    "        self.out = Dense(1, activation = \"linear\")\n",
    "\n",
    "    def call(self, input_data):\n",
    "        #Extract data\n",
    "        features, horizon_emb = input_data\n",
    "        #Calculate embedding\n",
    "        emb = self.embedding(horizon_emb)\n",
    "        emb = tf.squeeze(emb, axis = 1)\n",
    "        conc = Concatenate(axis = 1)([features, emb])\n",
    "        #Calculate output\n",
    "        output = self.hidden(conc)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9260e5d-229c-41e5-9411-64bb7c727707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, quantile, train_data, train_target, validation_data, batch_size, epochs, learning_rate):\n",
    "    #Define optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    #Early stopping\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5, min_delta = 1e-5)\n",
    "    #Compile model\n",
    "    model.compile(optimizer = optimizer, loss = lambda true,pred: pinball_loss(true, pred, tau = quantile))\n",
    "    model.fit(x = train_data, y = train_target, validation_data = validation_data, epochs = epochs, batch_size = batch_size, callbacks = [callback], shuffle = True, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b60d1f33-79ac-4881-8b89-c7afb299c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_models(train_data, train_target, validation_data, batch_size = BATCH_SIZE, epochs = EPOCHS, learning_rate = learning_rate, quantiles = quantiles):\n",
    "    models = []\n",
    "    for quantile in quantiles:\n",
    "        model = base_model()\n",
    "        train_model(model, quantile, train_data, train_target, validation_data, batch_size, epochs, learning_rate)\n",
    "        print(\"Training finished for quantile: {}\".format(quantile))\n",
    "        models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4835ea46-5637-496d-97a5-e22b4be0c6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for quantile: 0.025\n",
      "Training finished for quantile: 0.25\n",
      "Training finished for quantile: 0.5\n",
      "Training finished for quantile: 0.75\n",
      "Training finished for quantile: 0.975\n"
     ]
    }
   ],
   "source": [
    "trained_models = create_all_models(train_data, train_target, (val_data, val_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77040432-055d-4329-b3c5-832009a895bc",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35c449a-9d86-4c65-bf50-70fe9e426cd7",
   "metadata": {},
   "source": [
    "## Evaluate pinball loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d5b603f-9ae8-4e1c-ad60-3fe8cb878c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for cnt,_ in enumerate(quantiles):\n",
    "    pred = trained_models[cnt].predict(test_data)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de39b681-c77e-4eda-b524-ff7634070be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 0.010759788568865341\n",
      "Pinball loss for quantile 0.25 : \t 0.05284111797099202\n",
      "Pinball loss for quantile 0.5 : \t 0.06348985375610151\n",
      "Pinball loss for quantile 0.75 : \t 0.051627242298588345\n",
      "Pinball loss for quantile 0.975 : \t 0.009777059545692341\n"
     ]
    }
   ],
   "source": [
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = mean_pinball_loss(test_target.reshape(-1), predictions[cnt].reshape(-1), alpha = quantile)\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06d9e6-501e-4dc9-9774-e2eeb9f3df0d",
   "metadata": {},
   "source": [
    "## Evaluate pinball loss for naive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c292058-fa01-498e-947c-513092bb5be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 0.016267546765760324\n",
      "Pinball loss for quantile 0.25 : \t 0.05348726824203114\n",
      "Pinball loss for quantile 0.5 : \t 0.06471961764016104\n",
      "Pinball loss for quantile 0.75 : \t 0.0539318108743273\n",
      "Pinball loss for quantile 0.975 : \t 0.018099836010292032\n"
     ]
    }
   ],
   "source": [
    "naive_pred = np.quantile(test_data[0], quantiles, axis = 1)\n",
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = mean_pinball_loss(np.squeeze(test_target), naive_pred[cnt], alpha = quantile)\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f1cbc6-a34a-4719-bd4d-f164a8ae4029",
   "metadata": {},
   "source": [
    "## Check plausability of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdbf0f5a-5eed-4f66-b62a-c54cc195a909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile met for quantile = 0.025: \t 2.56 %\n",
      "Quantile met for quantile = 0.25: \t 26.44 %\n",
      "Quantile met for quantile = 0.5: \t 54.290000000000006 %\n",
      "Quantile met for quantile = 0.75: \t 81.12 %\n",
      "Quantile met for quantile = 0.975: \t 97.89 %\n"
     ]
    }
   ],
   "source": [
    "for cnt,pred in enumerate(predictions):\n",
    "    q_smaller = (pred > test_target).sum()\n",
    "    emp_quant = q_smaller / pred.size\n",
    "    print(\"Quantile met for quantile = {}: \\t {} %\".format(quantiles[cnt], np.round(emp_quant,4)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aa53c3-7838-4d56-b1df-d3bc626bdd52",
   "metadata": {},
   "source": [
    "# Predict new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e557515-41c9-4fff-8e2b-e9d3b44837de",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train on complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b9b4ac5-2dd0-44ce-89a4-4e7f3362d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = convert_format(train_val)\n",
    "val_data, val_target = convert_format(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39bec11b-7fba-4209-923d-85d082a1ec03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for quantile: 0.025\n",
      "Training finished for quantile: 0.25\n",
      "Training finished for quantile: 0.5\n",
      "Training finished for quantile: 0.75\n",
      "Training finished for quantile: 0.975\n"
     ]
    }
   ],
   "source": [
    "trained_models = create_all_models(train_data, train_target, (val_data, val_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c62998b-cc46-461b-b433-a5a42a637265",
   "metadata": {},
   "source": [
    "## Predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "766e47da-37bc-4465-b36a-1990b4820fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set current date\n",
    "current_date = (date.today()).strftime(\"%Y%m%d\")\n",
    "path = \"data/berlin_data/icon_data/icon-eu-eps_{}00_t_2m_Berlin.txt\".format(current_date)\n",
    "new_data = pd.read_csv(path.format(current_date.replace(\"-\",\"\")), skiprows = 3, sep = \"|\").dropna(axis = 1)\n",
    "new_data.columns = new_data.columns.str.replace(\" \", \"\")\n",
    "# Normalize and get horizons\n",
    "new_data = new_data[new_data[\"fcst_hour\"].isin(horizons)].to_numpy()\n",
    "new_data[:,1:] = feature_scaler.transform(new_data[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d47376d-15f3-41d4-bb62-7c6b26fd78b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = convert_format(new_data, predict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81cc69c7-8540-47c6-be2f-cfd97b244c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare dataframe\n",
    "final_prediction = pd.DataFrame(columns = [\"forecast_date\",\"target\",\"horizon\",\"q0.025\",\"q0.25\",\"q0.5\",\"q0.75\",\"q0.975\"], index = np.arange(0,5))\n",
    "final_prediction[\"forecast_date\"] = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "final_prediction[\"horizon\"] = [\"{} hour\".format(x) for x in horizons]\n",
    "final_prediction[\"target\"] = \"temperature\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa59a62f-fb9b-45e9-aa3e-cf8fbb366c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 408 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AD173D6160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 409 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001AD1795C040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "for cnt, quantile in enumerate(quantiles):\n",
    "    #Get prediction\n",
    "    prediction = trained_models[cnt].predict(pred_data)\n",
    "    #Retransform\n",
    "    final_pred = target_scaler.inverse_transform(prediction)\n",
    "    final_prediction.loc[:,\"q{}\".format(quantile)] = final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b85780f-828b-4b27-800f-a70956cf7b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>target</th>\n",
       "      <th>horizon</th>\n",
       "      <th>q0.025</th>\n",
       "      <th>q0.25</th>\n",
       "      <th>q0.5</th>\n",
       "      <th>q0.75</th>\n",
       "      <th>q0.975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>temperature</td>\n",
       "      <td>36 hour</td>\n",
       "      <td>0.715944</td>\n",
       "      <td>2.108084</td>\n",
       "      <td>3.170525</td>\n",
       "      <td>3.291906</td>\n",
       "      <td>6.084178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>temperature</td>\n",
       "      <td>48 hour</td>\n",
       "      <td>1.543389</td>\n",
       "      <td>3.172759</td>\n",
       "      <td>3.909042</td>\n",
       "      <td>4.293498</td>\n",
       "      <td>6.522366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>temperature</td>\n",
       "      <td>60 hour</td>\n",
       "      <td>2.961791</td>\n",
       "      <td>4.908102</td>\n",
       "      <td>5.713093</td>\n",
       "      <td>6.076737</td>\n",
       "      <td>8.300484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>temperature</td>\n",
       "      <td>72 hour</td>\n",
       "      <td>-0.238702</td>\n",
       "      <td>1.827929</td>\n",
       "      <td>2.436162</td>\n",
       "      <td>2.753498</td>\n",
       "      <td>5.474703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>temperature</td>\n",
       "      <td>84 hour</td>\n",
       "      <td>1.720604</td>\n",
       "      <td>3.900187</td>\n",
       "      <td>4.672521</td>\n",
       "      <td>5.175116</td>\n",
       "      <td>7.792253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  forecast_date       target  horizon    q0.025     q0.25      q0.5     q0.75  \\\n",
       "0    2021-11-24  temperature  36 hour  0.715944  2.108084  3.170525  3.291906   \n",
       "1    2021-11-24  temperature  48 hour  1.543389  3.172759  3.909042  4.293498   \n",
       "2    2021-11-24  temperature  60 hour  2.961791  4.908102  5.713093  6.076737   \n",
       "3    2021-11-24  temperature  72 hour -0.238702  1.827929  2.436162  2.753498   \n",
       "4    2021-11-24  temperature  84 hour  1.720604  3.900187  4.672521  5.175116   \n",
       "\n",
       "     q0.975  \n",
       "0  6.084178  \n",
       "1  6.522366  \n",
       "2  8.300484  \n",
       "3  5.474703  \n",
       "4  7.792253  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95977220-fde7-4cd4-a1e9-47330f8d52bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36    2.14\n",
       "48    2.84\n",
       "52    4.82\n",
       "56    1.17\n",
       "58    3.81\n",
       "Name: 0.5, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.read_csv(path.format(current_date.replace(\"-\",\"\")), skiprows = 3, sep = \"|\").dropna(axis = 1)\n",
    "new_data.columns = new_data.columns.str.replace(\" \", \"\")\n",
    "new_data[new_data[\"fcst_hour\"].isin(horizons)].quantile(0.5, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d25019c0-38cc-4bae-9aff-24414fda88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction.to_pickle(\"../evaluation/predictions/single/{}_{}\".format(\"temperature\", date.today().strftime(\"%Y-%m-%d\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd0d39-9e8d-446a-9ac6-c329c3bf9d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
