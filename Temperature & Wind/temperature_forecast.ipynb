{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dcc675b-a528-47d8-817d-66cd81b07b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date, datetime, timedelta\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.math import erf\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import Normalizer,StandardScaler, LabelEncoder\n",
    "from tensorflow_addons.losses import pinball_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a9d7181-beab-4222-974f-a5046a47ccc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4510d11-04a6-4c31-a2ec-0b842336dafc",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a7bd45-3634-4ef0-9ea6-38c2b9c97c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "horizons = [36, 48 ,60, 72, 84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3daf8141-c74c-4a94-8c48-d3a39cf41cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data():\n",
    "    \"\"\"\n",
    "    Load data, normalize and get data splits\n",
    "    \"\"\"\n",
    "    data = pd.read_pickle(\"data/complete_data_t_2m\")\n",
    "    data = data[data[\"fcst_hour\"].isin(horizons)]\n",
    "    data_np = data.iloc[:,3:-2].drop(\"obs_tm\", axis = 1).to_numpy()\n",
    "    #Create label encoding for embedding\n",
    "    label_enc = LabelEncoder()\n",
    "    encoding = label_enc.fit_transform(data_np[:,0])\n",
    "    data_np[:,0] = encoding\n",
    "    \n",
    "    Y = data_np[:,1]\n",
    "    X = np.delete(data_np, 1, axis = 1)\n",
    "    train_val_data_X, test_data_X, train_val_data_Y, test_data_Y = train_test_split(X,Y, test_size = 0.1)\n",
    "    train_data_X, val_data_X, train_data_Y,val_data_Y = train_test_split(train_val_data_X,train_val_data_Y, test_size = 0.2)\n",
    "\n",
    "    #Normalize features data based on train set\n",
    "    feature_normalizer = Normalizer()\n",
    "    emb = train_data_X[:,0]\n",
    "    train_data_X = feature_normalizer.fit_transform(train_data_X)\n",
    "    train_data_X[:,0] = emb\n",
    "    \n",
    "    emb = val_data_X[:,0]\n",
    "    val_data_X = feature_normalizer.transform(val_data_X)\n",
    "    val_data_X[:,0] = emb\n",
    "    \n",
    "    emb = test_data_X[:,0]\n",
    "    test_data_X = feature_normalizer.transform(test_data_X)\n",
    "    test_data_X[:,0] = emb\n",
    "    \n",
    "\n",
    "    #Normalize target and save retransform\n",
    "    target_scaler = StandardScaler()\n",
    "    train_data_Y = target_scaler.fit_transform(train_data_Y.reshape(-1,1))\n",
    "    val_data_Y = target_scaler.transform(val_data_Y.reshape(-1,1))\n",
    "    \n",
    "    return train_data_X, train_data_Y, val_data_X, val_data_Y, test_data_X, test_data_Y, feature_normalizer, target_scaler, label_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6c0048-357c-4145-9a03-f78d32d81a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, val_X, val_Y, test_X, test_Y, feature_scaler, target_scaler, label_encoder = get_split_data()\n",
    "no_features = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afe6315-fa3a-4000-a2de-7c7714564f6e",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c401b24-2bb3-4032-8387-68d8759625eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps_cost_function(y_true, y_pred):\n",
    "    \"\"\"Compute the CRPS cost function for a normal distribution defined by\n",
    "    the mean and standard deviation.\n",
    "    Code inspired by Kai Polsterer (HITS).\n",
    "    Args:\n",
    "        y_true: True values\n",
    "        y_pred: Tensor containing predictions: [mean, std]\n",
    "    Returns:\n",
    "        mean_crps: Scalar with mean CRPS over batch\n",
    "    \"\"\"\n",
    "\n",
    "    # Split input\n",
    "    mu = y_pred[:, 0]\n",
    "    sigma = y_pred[:, 1]\n",
    "    y_true = y_true[:, 0]   # Need to also get rid of axis 1 to match!\n",
    "\n",
    "    # To stop sigma from becoming negative we first have to \n",
    "    # convert it the the variance and then take the square\n",
    "    # root again. \n",
    "    var = K.square(sigma)\n",
    "    # The following three variables are just for convenience\n",
    "    loc = (y_true - mu) / K.sqrt(var)\n",
    "    phi = 1.0 / np.sqrt(2.0 * np.pi) * K.exp(-K.square(loc) / 2.0)\n",
    "    Phi = 0.5 * (1.0 + erf(loc / np.sqrt(2.0)))\n",
    "    # First we will compute the crps for each input/target pair\n",
    "    crps =  K.sqrt(var) * (loc * (2. * Phi - 1.) + 2 * phi - 1. / np.sqrt(np.pi))\n",
    "    # Then we take the mean. The cost is now a scalar\n",
    "    return K.mean(crps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "650ec674-e165-43a9-b763-fe6b866ac6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_model(train_X, train_Y, no_features, n_embeddings = 65, no_outputs = 2):\n",
    "    \"\"\"\n",
    "    trainX -- input values; shape: [number of samples, no_features]\n",
    "    trainY -- output values; shape: [number of samples, 2\n",
    "    \"\"\"    \n",
    "    inp = Input(shape = no_features+1)\n",
    "    #Extract embedding features\n",
    "    horizon = inp[:,0]\n",
    "    features = inp[:,1:]\n",
    "    \n",
    "    #Embedding layer\n",
    "    horizon_emb = Embedding(input_dim = n_embeddings, output_dim = 4)(horizon)\n",
    "    \n",
    "    #Concatenate\n",
    "    conc = Concatenate(axis = 1)([features,horizon_emb])\n",
    "    \n",
    "    #Hidden layer\n",
    "    #hidden = Dense(30, activation = \"relu\")(conc)\n",
    "    \n",
    "    #Linear layer\n",
    "    outputs = Dense(no_outputs, activation = \"linear\")(conc)\n",
    "    model = Model(inputs = inp, outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b60d1f33-79ac-4881-8b89-c7afb299c20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 41)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None,)              0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli (None, 40)           0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 4)            260         tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 44)           0           tf.__operators__.getitem_3[0][0] \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            90          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 350\n",
      "Trainable params: 350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = basic_model(train_X, train_Y, no_features)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4835ea46-5637-496d-97a5-e22b4be0c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_X, train_Y, val_X, val_Y, no_features, batch_size, epochs, learning_rate):\n",
    "    #Define optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    #Early stopping\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta = 1e-5)\n",
    "    #Compile model\n",
    "    model.compile(optimizer = optimizer, loss = crps_cost_function)\n",
    "    model.fit(train_X, train_Y, validation_data = (val_X, val_Y), epochs = EPOCHS, shuffle = True, callbacks = [callback], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d5693de-5bd9-4505-8f77-d53e444e144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd58e03d-28a3-417e-90e9-55302e6b1d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.5794 - val_loss: 0.5153\n",
      "Epoch 2/20\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4828 - val_loss: 0.5101\n",
      "Epoch 3/20\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4860 - val_loss: 0.5050\n",
      "Epoch 4/20\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4938 - val_loss: 0.5104\n",
      "Epoch 5/20\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4824 - val_loss: 0.5159\n",
      "Epoch 6/20\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4862 - val_loss: 0.5048\n",
      "Epoch 7/20\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4843 - val_loss: 0.5056\n",
      "Epoch 8/20\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4900 - val_loss: 0.5033\n",
      "Epoch 9/20\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4872 - val_loss: 0.5046\n",
      "Epoch 10/20\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4795 - val_loss: 0.5087\n",
      "Epoch 11/20\n",
      "115/115 [==============================] - 1s 5ms/step - loss: 0.4924 - val_loss: 0.5038\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_X, train_Y, val_X, val_Y, no_features, BATCH_SIZE, EPOCHS, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77040432-055d-4329-b3c5-832009a895bc",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "724836a2-5f92-4664-b412-43891791b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get prediction\n",
    "pred = model.predict(test_X)\n",
    "#Retransform\n",
    "pred = target_scaler.inverse_transform(pred)\n",
    "#Square and root results\n",
    "pred[:,1] = np.sqrt(pred[:,1]**2)\n",
    "#Convert prediction to quantiles\n",
    "quantile_pred = np.zeros(shape = (pred.shape[0],5))\n",
    "for cnt,x in enumerate(pred):\n",
    "    quantile_pred[cnt] = norm.ppf(quantiles, loc = x[0], scale = x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b24ba71-ee97-4905-a7d1-d7b12b7e6afc",
   "metadata": {},
   "source": [
    "## Evaluate data on realizations with pinball loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ed30c23-c19a-4ab9-a2e4-886ae8a7a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 10.448966871802623\n",
      "Pinball loss for quantile 0.25 : \t 4.021949171387535\n",
      "Pinball loss for quantile 0.5 : \t 2.8082806756917167\n",
      "Pinball loss for quantile 0.75 : \t 4.28190508402882\n",
      "Pinball loss for quantile 0.975 : \t 10.800654002513532\n"
     ]
    }
   ],
   "source": [
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = pinball_loss(np.squeeze(test_Y), quantile_pred[:,cnt], tau = quantile).numpy()\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06d9e6-501e-4dc9-9774-e2eeb9f3df0d",
   "metadata": {},
   "source": [
    "## Evaluate naive forecast on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c292058-fa01-498e-947c-513092bb5be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 11.854709349713774\n",
      "Pinball loss for quantile 0.25 : \t 9.135340685132531\n",
      "Pinball loss for quantile 0.5 : \t 6.1332384326141165\n",
      "Pinball loss for quantile 0.75 : \t 3.139491149143128\n",
      "Pinball loss for quantile 0.975 : \t 0.4557208223256731\n"
     ]
    }
   ],
   "source": [
    "naive_pred = np.quantile(test_X[:,1:], quantiles, axis = 1)\n",
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = pinball_loss(np.squeeze(test_Y), naive_pred[cnt], tau = quantile).numpy()\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aa53c3-7838-4d56-b1df-d3bc626bdd52",
   "metadata": {},
   "source": [
    "# Predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d1fd937-e836-484f-9908-e63656c5de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_data(name):\n",
    "    if name == \"temperature\":\n",
    "        method = \"t_2m\"\n",
    "    elif name == \"wind\":\n",
    "        method = \"wind_mean_10m\"\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "        return None\n",
    "    #Set current date\n",
    "    current_date = date.today().strftime(\"%Y%m%d\")\n",
    "    path = \"data/icon_data/icon-eu-eps_{}00_{}_Karlsruhe.txt\".format(current_date, method)\n",
    "    new_data = pd.read_csv(path.format(current_date.replace(\"-\",\"\")), skiprows = 3, sep = \"|\").dropna(axis = 1)\n",
    "    new_data.columns = new_data.columns.str.replace(\" \", \"\")\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "661acb48-8b63-46ac-9ae6-a3fe78746d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_forecast(name, horizons, feature_scaler, label_encoder, model, save = False):\n",
    "    if name == \"temperature\":\n",
    "        method = \"t_2m\"\n",
    "    elif name == \"wind\":\n",
    "        method = \"wind_mean_10m\"\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "        return None\n",
    "    #Get data\n",
    "    data = get_pred_data(name)\n",
    "    data = data[data[\"fcst_hour\"].isin(horizons)].to_numpy()\n",
    "    #Label encoding\n",
    "    encoding = label_encoder.transform(data[:,0])\n",
    "    data[:,0] = encoding\n",
    "    #Normalize\n",
    "    data_pred = feature_scaler.transform(data)\n",
    "    #Predict\n",
    "    pred = model.predict(data_pred)\n",
    "    pred = target_scaler.inverse_transform(pred)\n",
    "    \n",
    "    #Create final prediction dataframe\n",
    "    final_prediction = pd.DataFrame(columns = [\"forecast_date\",\"target\",\"horizon\",\"q0.025\",\"q0.25\",\"q0.5\",\"q0.75\",\"q0.975\"], index = np.arange(0,5))\n",
    "    final_prediction[\"forecast_date\"] = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "    final_prediction[\"horizon\"] = [\"{} hour\".format(x) for x in horizons]\n",
    "    final_prediction[\"target\"] = name\n",
    "    \n",
    "    #Save prediction to dataframe\n",
    "    for cnt,x in enumerate(pred):\n",
    "        final_prediction.loc[final_prediction[\"horizon\"] == \"{} hour\".format(horizons[cnt]), final_prediction.columns[3:]] = (norm.ppf(quantiles, loc = x[0], scale = x[1]))\n",
    "        \n",
    "    #Save prediction\n",
    "    if save == True:\n",
    "        final_prediction.to_pickle(\"../evaluation/predictions/single/{}_{}\".format(name, date.today().strftime(\"%Y-%m-%d\")))\n",
    "    \n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f21ff9e-c155-44cb-83a4-cf729a688a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>target</th>\n",
       "      <th>horizon</th>\n",
       "      <th>q0.025</th>\n",
       "      <th>q0.25</th>\n",
       "      <th>q0.5</th>\n",
       "      <th>q0.75</th>\n",
       "      <th>q0.975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>temperature</td>\n",
       "      <td>36 hour</td>\n",
       "      <td>7.749705</td>\n",
       "      <td>12.469254</td>\n",
       "      <td>14.945606</td>\n",
       "      <td>17.421959</td>\n",
       "      <td>22.141507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>temperature</td>\n",
       "      <td>48 hour</td>\n",
       "      <td>8.210411</td>\n",
       "      <td>12.86936</td>\n",
       "      <td>15.313915</td>\n",
       "      <td>17.758471</td>\n",
       "      <td>22.41742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>temperature</td>\n",
       "      <td>60 hour</td>\n",
       "      <td>7.572976</td>\n",
       "      <td>12.420759</td>\n",
       "      <td>14.964396</td>\n",
       "      <td>17.508033</td>\n",
       "      <td>22.355815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>temperature</td>\n",
       "      <td>72 hour</td>\n",
       "      <td>9.263561</td>\n",
       "      <td>13.214089</td>\n",
       "      <td>15.286936</td>\n",
       "      <td>17.359782</td>\n",
       "      <td>21.31031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-27</td>\n",
       "      <td>temperature</td>\n",
       "      <td>84 hour</td>\n",
       "      <td>8.018155</td>\n",
       "      <td>12.672376</td>\n",
       "      <td>15.11445</td>\n",
       "      <td>17.556525</td>\n",
       "      <td>22.210746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  forecast_date       target  horizon    q0.025      q0.25       q0.5  \\\n",
       "0    2021-10-27  temperature  36 hour  7.749705  12.469254  14.945606   \n",
       "1    2021-10-27  temperature  48 hour  8.210411   12.86936  15.313915   \n",
       "2    2021-10-27  temperature  60 hour  7.572976  12.420759  14.964396   \n",
       "3    2021-10-27  temperature  72 hour  9.263561  13.214089  15.286936   \n",
       "4    2021-10-27  temperature  84 hour  8.018155  12.672376   15.11445   \n",
       "\n",
       "       q0.75     q0.975  \n",
       "0  17.421959  22.141507  \n",
       "1  17.758471   22.41742  \n",
       "2  17.508033  22.355815  \n",
       "3  17.359782   21.31031  \n",
       "4  17.556525  22.210746  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_final_forecast(\"temperature\",horizons, feature_scaler, label_encoder, model, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6167c5-1ee3-4b5f-9d2d-5645f801ff73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
