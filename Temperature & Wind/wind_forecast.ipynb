{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c87b87-6742-42a5-a360-caf0067f0a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date, datetime, timedelta\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras.backend as K\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import Normalizer,StandardScaler, LabelEncoder\n",
    "from tensorflow_addons.losses import pinball_loss\n",
    "from sklearn.metrics import mean_pinball_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b058c-cc23-4ea4-8879-2fa0d4454cc4",
   "metadata": {},
   "source": [
    "# Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d46b04-690f-4c5e-9826-865a90030282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>init_tm</th>\n",
       "      <th>met_var</th>\n",
       "      <th>location</th>\n",
       "      <th>fcst_hour</th>\n",
       "      <th>obs_tm</th>\n",
       "      <th>obs</th>\n",
       "      <th>ens_1</th>\n",
       "      <th>ens_2</th>\n",
       "      <th>ens_3</th>\n",
       "      <th>ens_4</th>\n",
       "      <th>...</th>\n",
       "      <th>ens_33</th>\n",
       "      <th>ens_34</th>\n",
       "      <th>ens_35</th>\n",
       "      <th>ens_36</th>\n",
       "      <th>ens_37</th>\n",
       "      <th>ens_38</th>\n",
       "      <th>ens_39</th>\n",
       "      <th>ens_40</th>\n",
       "      <th>ens_mean</th>\n",
       "      <th>ens_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.80</td>\n",
       "      <td>6.56</td>\n",
       "      <td>4.54</td>\n",
       "      <td>5.05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.59</td>\n",
       "      <td>5.45</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.47</td>\n",
       "      <td>5.99</td>\n",
       "      <td>3.48</td>\n",
       "      <td>4.92</td>\n",
       "      <td>5.09</td>\n",
       "      <td>4.58675</td>\n",
       "      <td>0.565448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-12-18 01:00:00+00:00</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.68</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.06</td>\n",
       "      <td>5.33</td>\n",
       "      <td>...</td>\n",
       "      <td>4.92</td>\n",
       "      <td>5.18</td>\n",
       "      <td>4.98</td>\n",
       "      <td>4.88</td>\n",
       "      <td>6.39</td>\n",
       "      <td>3.74</td>\n",
       "      <td>5.18</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.69750</td>\n",
       "      <td>0.663747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2018-12-18 02:00:00+00:00</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.28</td>\n",
       "      <td>7.10</td>\n",
       "      <td>5.39</td>\n",
       "      <td>5.44</td>\n",
       "      <td>...</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.88</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.80</td>\n",
       "      <td>6.66</td>\n",
       "      <td>4.14</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.81650</td>\n",
       "      <td>0.830100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018-12-18 03:00:00+00:00</td>\n",
       "      <td>5.04</td>\n",
       "      <td>3.47</td>\n",
       "      <td>7.45</td>\n",
       "      <td>6.11</td>\n",
       "      <td>5.66</td>\n",
       "      <td>...</td>\n",
       "      <td>5.37</td>\n",
       "      <td>4.58</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.86</td>\n",
       "      <td>6.96</td>\n",
       "      <td>4.41</td>\n",
       "      <td>5.26</td>\n",
       "      <td>4.74</td>\n",
       "      <td>5.01625</td>\n",
       "      <td>1.222111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-18 00:00:00+00:00</td>\n",
       "      <td>wind_10m</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018-12-18 04:00:00+00:00</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.56</td>\n",
       "      <td>8.02</td>\n",
       "      <td>6.29</td>\n",
       "      <td>5.81</td>\n",
       "      <td>...</td>\n",
       "      <td>5.30</td>\n",
       "      <td>4.05</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.26</td>\n",
       "      <td>6.67</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.56</td>\n",
       "      <td>5.01600</td>\n",
       "      <td>1.355050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    init_tm   met_var location  fcst_hour  \\\n",
       "0 2018-12-18 00:00:00+00:00  wind_10m   Berlin        0.0   \n",
       "1 2018-12-18 00:00:00+00:00  wind_10m   Berlin        1.0   \n",
       "2 2018-12-18 00:00:00+00:00  wind_10m   Berlin        2.0   \n",
       "3 2018-12-18 00:00:00+00:00  wind_10m   Berlin        3.0   \n",
       "4 2018-12-18 00:00:00+00:00  wind_10m   Berlin        4.0   \n",
       "\n",
       "                     obs_tm   obs  ens_1  ens_2  ens_3  ens_4  ...  ens_33  \\\n",
       "0 2018-12-18 00:00:00+00:00  6.48   3.80   6.56   4.54   5.05  ...    5.59   \n",
       "1 2018-12-18 01:00:00+00:00  6.12   3.68   7.03   5.06   5.33  ...    4.92   \n",
       "2 2018-12-18 02:00:00+00:00  4.32   3.28   7.10   5.39   5.44  ...    4.91   \n",
       "3 2018-12-18 03:00:00+00:00  5.04   3.47   7.45   6.11   5.66  ...    5.37   \n",
       "4 2018-12-18 04:00:00+00:00  6.48   3.56   8.02   6.29   5.81  ...    5.30   \n",
       "\n",
       "   ens_34  ens_35  ens_36  ens_37  ens_38  ens_39  ens_40  ens_mean   ens_var  \n",
       "0    5.45    5.30    4.47    5.99    3.48    4.92    5.09   4.58675  0.565448  \n",
       "1    5.18    4.98    4.88    6.39    3.74    5.18    4.85   4.69750  0.663747  \n",
       "2    4.88    5.20    4.80    6.66    4.14    5.05    4.80   4.81650  0.830100  \n",
       "3    4.58    5.30    4.86    6.96    4.41    5.26    4.74   5.01625  1.222111  \n",
       "4    4.05    5.04    5.26    6.67    4.86    4.95    4.56   5.01600  1.355050  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_feather(\"data/berlin_data/historic_data/icon_eps_wind_10m.feather\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a61ef2-6979-4c75-b699-8ab25c8b97cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.025, 0.25, 0.5, 0.75, 0.975]\n",
    "horizons = [36, 48 ,60, 72, 84]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4b5481-eb7e-49ca-afec-58682f55ec56",
   "metadata": {},
   "source": [
    "## Change data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d44c2a-f067-4510-b9be-7c75f028330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    data_prep = data.dropna().copy()\n",
    "    data_prep.drop([\"init_tm\", \"met_var\", \"location\", \"ens_mean\", \"ens_var\", \"obs_tm\"], axis = 1, inplace = True)\n",
    "    return data_prep.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f126faa5-7653-40c0-8747-891f31410285",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = prepare_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b102af7-0f3f-4a64-a4a9-5ca473ece0e7",
   "metadata": {},
   "source": [
    "## Train, val, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e235d099-c210-4ffd-8f05-ded00a446025",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(data_np, test_size = 0.2)\n",
    "train, val = train_test_split(train_val, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d7426d-03b3-45db-89db-c30902fb7655",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b72e22d-2362-4c63-a868-8c373b12890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, feature_scaler = None, target_scaler = None, learn = False):\n",
    "    if learn == True:\n",
    "        feature_scaler = StandardScaler()\n",
    "        target_scaler = StandardScaler()\n",
    "        #Learn target scaling\n",
    "        target_scaled = target_scaler.fit_transform(data[:,1].reshape(-1,1))\n",
    "        #Learn feature scaling\n",
    "        feature_scaled = feature_scaler.fit_transform(data[:,2:])\n",
    "        #Append\n",
    "        data[:,1] = target_scaled.reshape(-1)\n",
    "        data[:,2:] = feature_scaled\n",
    "        \n",
    "        return data, feature_scaler, target_scaler\n",
    "    \n",
    "    else:\n",
    "        #Scale target\n",
    "        target_scaled = target_scaler.transform(data[:,1].reshape(-1,1))\n",
    "        #Scale features\n",
    "        feature_scaled = feature_scaler.transform(data[:,2:])\n",
    "        #Append\n",
    "        data[:,1] = target_scaled.reshape(-1)\n",
    "        data[:,2:] = feature_scaled\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e886bd-d209-4638-b8dc-2200bf8d96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, feature_scaler, target_scaler = normalize(train, learn = True)\n",
    "train_val = normalize(train_val, feature_scaler, target_scaler)\n",
    "test = normalize(test, feature_scaler, target_scaler)\n",
    "val = normalize(val, feature_scaler, target_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba78957c-9346-45cf-bfe3-6fd950b6e17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_format(input_data, predict = False):\n",
    "    #Extract forecast embedding\n",
    "    horizon_emb = input_data[:,0]\n",
    "    \n",
    "    if predict == False:        \n",
    "        #Extract features\n",
    "        features = input_data[:,2:]\n",
    "        # Extract target\n",
    "        target = np.expand_dims(input_data[:,1],1)\n",
    "        return [features, horizon_emb], target\n",
    "    else:\n",
    "        #Extract features\n",
    "        features = input_data[:,1:]\n",
    "        return [features, horizon_emb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f64c0313-aaba-4927-b7e0-c028ef2871de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = convert_format(train)\n",
    "val_data, val_target = convert_format(val)\n",
    "test_data, test_target = convert_format(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f9a31-842f-4af8-9e5e-65938d9aa29c",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6330b732-4945-4fee-928d-68ce05bc9ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "EPOCHS = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "427ab472-e25f-4453-85e6-b2b6d58ced77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class base_model(tf.keras.Model):    \n",
    "    def __init__(self, n_embeddings = 121):\n",
    "        super(base_model, self).__init__()\n",
    "        #Embedding layers\n",
    "        self.embedding = Embedding(input_dim = n_embeddings, output_dim = 4)\n",
    "        #Create Dense layers\n",
    "        self.hidden = Dense(25, activation = \"relu\")\n",
    "        self.out = Dense(1, activation = \"linear\")\n",
    "\n",
    "    def call(self, input_data):\n",
    "        #Extract data\n",
    "        features, horizon_emb = input_data\n",
    "        #Calculate embedding\n",
    "        emb = self.embedding(horizon_emb)\n",
    "        emb = tf.squeeze(emb, axis = 1)\n",
    "        conc = Concatenate(axis = 1)([features, emb])\n",
    "        #Calculate output\n",
    "        output = self.hidden(conc)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b4d25cb-4755-48e8-a7fd-347750d86b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, quantile, train_data, train_target, validation_data, batch_size, epochs, learning_rate):\n",
    "    #Define optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    #Early stopping\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 5, min_delta = 1e-5)\n",
    "    #Compile model\n",
    "    model.compile(optimizer = optimizer, loss = lambda true,pred: pinball_loss(true, pred, tau = quantile))\n",
    "    model.fit(x = train_data, y = train_target, validation_data = validation_data, epochs = epochs, batch_size = batch_size, callbacks = [callback], shuffle = True, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4887da3d-afaf-42dd-b6b6-b9bf47dfbfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_models(train_data, train_target, validation_data, batch_size = BATCH_SIZE, epochs = EPOCHS, learning_rate = learning_rate, quantiles = quantiles):\n",
    "    models = []\n",
    "    for quantile in quantiles:\n",
    "        model = base_model()\n",
    "        train_model(model, quantile, train_data, train_target, validation_data, batch_size, epochs, learning_rate)\n",
    "        print(\"Training finished for quantile: {}\".format(quantile))\n",
    "        models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e329a18-d85e-4f3f-908d-136deefda713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for quantile: 0.025\n",
      "Training finished for quantile: 0.25\n",
      "Training finished for quantile: 0.5\n",
      "Training finished for quantile: 0.75\n",
      "Training finished for quantile: 0.975\n"
     ]
    }
   ],
   "source": [
    "trained_models = create_all_models(train_data, train_target, (val_data, val_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b654dc1-0fad-4efa-a1b2-7555e6a901e1",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e9db2-9a20-48f2-a977-e6ccff02f431",
   "metadata": {},
   "source": [
    "## Evaluate pinball loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ead8f99c-60e7-45a6-a3fd-aaaea5dfc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for cnt,_ in enumerate(quantiles):\n",
    "    pred = trained_models[cnt].predict(test_data)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "633d0669-31d8-4edc-be3a-d3cce8bae007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 0.030956833640244756\n",
      "Pinball loss for quantile 0.25 : \t 0.17760619901923033\n",
      "Pinball loss for quantile 0.5 : \t 0.23243169317948134\n",
      "Pinball loss for quantile 0.75 : \t 0.1962447915487555\n",
      "Pinball loss for quantile 0.975 : \t 0.04100574731183313\n"
     ]
    }
   ],
   "source": [
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = mean_pinball_loss(test_target.reshape(-1), predictions[cnt].reshape(-1), alpha = quantile)\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa09f86-cb04-4800-9728-857028132e40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate pinball loss on naive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b851be17-c49d-4e57-a717-1ac1ce11924a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinball loss for quantile 0.025 : \t 0.0647317374172509\n",
      "Pinball loss for quantile 0.25 : \t 0.1983198203813224\n",
      "Pinball loss for quantile 0.5 : \t 0.24053620690484442\n",
      "Pinball loss for quantile 0.75 : \t 0.2042435030484134\n",
      "Pinball loss for quantile 0.975 : \t 0.07195176549333265\n"
     ]
    }
   ],
   "source": [
    "naive_pred = np.quantile(test_data[0], quantiles, axis = 1)\n",
    "for cnt,quantile in enumerate(quantiles):\n",
    "    loss = mean_pinball_loss(np.squeeze(test_target), naive_pred[cnt], alpha = quantile)\n",
    "    print(\"Pinball loss for quantile {} : \\t {}\".format(quantile,loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c2145-f06a-442b-8b86-93bb13424025",
   "metadata": {},
   "source": [
    "## Check plausability of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40555fc2-d96c-4a92-a0d5-1f87e42470f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile met for quantile = 0.025: \t 1.9800000000000002 %\n",
      "Quantile met for quantile = 0.25: \t 24.22 %\n",
      "Quantile met for quantile = 0.5: \t 49.66 %\n",
      "Quantile met for quantile = 0.75: \t 74.49 %\n",
      "Quantile met for quantile = 0.975: \t 96.69 %\n"
     ]
    }
   ],
   "source": [
    "for cnt,pred in enumerate(predictions):\n",
    "    q_smaller = (pred > test_target).sum()\n",
    "    emp_quant = q_smaller / pred.size\n",
    "    print(\"Quantile met for quantile = {}: \\t {} %\".format(quantiles[cnt], np.round(emp_quant,4)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d783c6-3f85-4823-ad89-88dfbd54e954",
   "metadata": {},
   "source": [
    "# Predict new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d822308c-2d0b-4fb6-9874-f9dba32d4668",
   "metadata": {},
   "source": [
    "## Train on complete data without test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5d0d281-5cd3-43bc-97e3-1b3495246f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = convert_format(train_val)\n",
    "val_data, val_target = convert_format(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f76d614f-64cf-4def-819f-f6cec92f3e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished for quantile: 0.025\n",
      "Training finished for quantile: 0.25\n",
      "Training finished for quantile: 0.5\n",
      "Training finished for quantile: 0.75\n",
      "Training finished for quantile: 0.975\n"
     ]
    }
   ],
   "source": [
    "trained_models = create_all_models(train_data, train_target, (val_data, val_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e586b-40b4-47dd-8052-86281866f51a",
   "metadata": {},
   "source": [
    "## Predict new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f2a45c8-da64-4fde-9446-3280324a6018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set current date\n",
    "current_date = date.today().strftime(\"%Y%m%d\")\n",
    "path = \"data/berlin_data/icon_data/icon-eu-eps_{}00_wind_mean_10m_Berlin.txt\".format(current_date)\n",
    "new_data = pd.read_csv(path.format(current_date.replace(\"-\",\"\")), skiprows = 3, sep = \"|\").dropna(axis = 1)\n",
    "new_data.columns = new_data.columns.str.replace(\" \", \"\")\n",
    "# Normalize and get horizons\n",
    "new_data = new_data[new_data[\"fcst_hour\"].isin(horizons)].to_numpy()\n",
    "new_data[:,1:] = feature_scaler.transform(new_data[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15935e68-3d66-4718-891d-c07b28dddb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = convert_format(new_data, predict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbc89af2-ff03-4ee4-a1e0-62fbd5d7998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare dataframe\n",
    "final_prediction = pd.DataFrame(columns = [\"forecast_date\",\"target\",\"horizon\",\"q0.025\",\"q0.25\",\"q0.5\",\"q0.75\",\"q0.975\"], index = np.arange(0,5))\n",
    "final_prediction[\"forecast_date\"] = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "final_prediction[\"horizon\"] = [\"{} hour\".format(x) for x in horizons]\n",
    "final_prediction[\"target\"] = \"wind\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f8bcdbe-043d-4e3d-b7e6-fd5ae42a6882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 404 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000259167F3040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 405 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000025916DB88B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "for cnt, quantile in enumerate(quantiles):\n",
    "    #Get prediction\n",
    "    prediction = trained_models[cnt].predict(pred_data)\n",
    "    #Retransform\n",
    "    final_pred = target_scaler.inverse_transform(prediction)\n",
    "    final_prediction.loc[:,\"q{}\".format(quantile)] = final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a12ec3ef-a08b-4962-850f-5882ed486b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_date</th>\n",
       "      <th>target</th>\n",
       "      <th>horizon</th>\n",
       "      <th>q0.025</th>\n",
       "      <th>q0.25</th>\n",
       "      <th>q0.5</th>\n",
       "      <th>q0.75</th>\n",
       "      <th>q0.975</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>wind</td>\n",
       "      <td>36 hour</td>\n",
       "      <td>6.291183</td>\n",
       "      <td>10.456472</td>\n",
       "      <td>12.625645</td>\n",
       "      <td>14.613970</td>\n",
       "      <td>19.014479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>wind</td>\n",
       "      <td>48 hour</td>\n",
       "      <td>8.303682</td>\n",
       "      <td>12.899690</td>\n",
       "      <td>14.896458</td>\n",
       "      <td>18.187073</td>\n",
       "      <td>22.069714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>wind</td>\n",
       "      <td>60 hour</td>\n",
       "      <td>6.005039</td>\n",
       "      <td>11.021708</td>\n",
       "      <td>11.242007</td>\n",
       "      <td>14.934902</td>\n",
       "      <td>22.125204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>wind</td>\n",
       "      <td>72 hour</td>\n",
       "      <td>4.366765</td>\n",
       "      <td>10.022429</td>\n",
       "      <td>14.965999</td>\n",
       "      <td>19.421743</td>\n",
       "      <td>24.736071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-24</td>\n",
       "      <td>wind</td>\n",
       "      <td>84 hour</td>\n",
       "      <td>5.366802</td>\n",
       "      <td>12.509247</td>\n",
       "      <td>14.081431</td>\n",
       "      <td>18.042637</td>\n",
       "      <td>26.089764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  forecast_date target  horizon    q0.025      q0.25       q0.5      q0.75  \\\n",
       "0    2021-11-24   wind  36 hour  6.291183  10.456472  12.625645  14.613970   \n",
       "1    2021-11-24   wind  48 hour  8.303682  12.899690  14.896458  18.187073   \n",
       "2    2021-11-24   wind  60 hour  6.005039  11.021708  11.242007  14.934902   \n",
       "3    2021-11-24   wind  72 hour  4.366765  10.022429  14.965999  19.421743   \n",
       "4    2021-11-24   wind  84 hour  5.366802  12.509247  14.081431  18.042637   \n",
       "\n",
       "      q0.975  \n",
       "0  19.014479  \n",
       "1  22.069714  \n",
       "2  22.125204  \n",
       "3  24.736071  \n",
       "4  26.089764  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e40dc3ca-e8f4-4e7c-a32e-af2aa2cc998f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36     9.91\n",
       "48    12.60\n",
       "52    10.41\n",
       "56     9.84\n",
       "58    11.07\n",
       "Name: 0.5, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.read_csv(path.format(current_date.replace(\"-\",\"\")), skiprows = 3, sep = \"|\").dropna(axis = 1)\n",
    "new_data.columns = new_data.columns.str.replace(\" \", \"\")\n",
    "new_data[new_data[\"fcst_hour\"].isin(horizons)].quantile(0.5, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5cb1ee4-677a-4e33-9ec9-8b72640e3806",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction.to_pickle(\"../evaluation/predictions/single/{}_{}\".format(\"wind\", date.today().strftime(\"%Y-%m-%d\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9781749-57e9-4ecf-ab6b-1dd01c4d5dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
